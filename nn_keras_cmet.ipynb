{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/37ce9e0096114a6dad158e8aa8ef3683\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# import comet_ml at the top of your file\n",
    "from comet_ml import Experiment\n",
    "import comet_ml\n",
    "import logging\n",
    "# Create an experiment with your api key\n",
    "experiment = Experiment(\n",
    "    project_name=\"digit-recognizer\",\n",
    "    workspace=\"wodenwang820118\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(\"comet_ml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow 2.7 \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input,Flatten,Dense,Dropout,BatchNormalization\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the numeric data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "\n",
       "[1 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train=pd.read_csv('train.csv')\n",
    "df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['label']\n",
    "X = df_train.drop('label', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 4, 7, 3, 5, 8, 9, 2, 6], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((28140, 784), (28140,), (13860, 784), (13860,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='val_loss',patience=10,restore_best_weights=True)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.7, patience=3, verbose=1, mode='auto', min_delta=0.00001, cooldown=0, min_lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DigitClassifier:\n",
    "    def __init__(self,X_train,X_test,y_train,y_test,early_stop,reduce_lr,experiment):\n",
    "        self.X_train = X_train\n",
    "        self.X_test = X_test\n",
    "        self.y_train = y_train\n",
    "        self.y_test = y_test\n",
    "        self.reduce_lr = reduce_lr\n",
    "        self.early_stop = early_stop\n",
    "        self.experiment = experiment\n",
    "    \n",
    "    def build_model(self):\n",
    "        # Build the model\n",
    "        model = Sequential()\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=self.experiment.get_parameter(\"first_layer_units\"),\n",
    "                input_shape=(self.X_train.shape[1],)\n",
    "            )\n",
    "        )\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Activation(activations.elu))\n",
    "        model.add(Dropout(self.experiment.get_parameter(\"first_layer_dropout_rate\")))\n",
    "\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=self.experiment.get_parameter(\"second_layer_units\"),\n",
    "                )\n",
    "            )\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Activation(activations.elu))\n",
    "        model.add(Dropout(self.experiment.get_parameter(\"second_layer_dropout_rate\")))\n",
    "\n",
    "        model.add(\n",
    "            Dense(\n",
    "                units=self.experiment.get_parameter(\"third_layer_units\"),\n",
    "                )\n",
    "            )\n",
    "        model.add(BatchNormalization())\n",
    "        model.add(layers.Activation(activations.elu))\n",
    "        model.add(Dropout(self.experiment.get_parameter(\"third_layer_dropout_rate\")))\n",
    "        \n",
    "        model.add(Dense(10,activation='softmax'))\n",
    "        optimizer = keras.optimizers.Adam(0.001)\n",
    "        model.compile(\n",
    "            optimizer=optimizer,\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def train_model(self):\n",
    "        # Train the model\n",
    "        model = self.build_model()\n",
    "        model.fit(\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            batch_size=self.experiment.get_parameter(\"batch_size\"),\n",
    "            epochs=self.experiment.get_parameter(\"epochs\"),\n",
    "            validation_data=(self.X_test,self.y_test),\n",
    "            callbacks=[self.early_stop,self.reduce_lr]\n",
    "        )\n",
    "        return model\n",
    "    \n",
    "    def evaluate_model(self):\n",
    "        # Evaluate the model\n",
    "        model = self.train_model()\n",
    "        score = model.evaluate(self.X_test,self.y_test)\n",
    "        LOGGER.info(f\"{ score }\")\n",
    "    \n",
    "    def grid_search(self, config_dict):\n",
    "        opt = comet_ml.Optimizer(config_dict)\n",
    "        for self.experiment in opt.get_experiments(project_name=\"digit-recognizer\"):\n",
    "            self.experiment.log_parameters(\"epochs\", 10)\n",
    "\n",
    "            self.build_model()\n",
    "            self.train_model()\n",
    "            self.evaluate_model()\n",
    "            self.experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: COMET_OPTIMIZER_ID=d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO: Using optimizer config: {'algorithm': 'bayes', 'configSpaceSize': 201600, 'endTime': None, 'id': 'd222a9ceb83e44b695c6f48cd870af98', 'lastUpdateTime': None, 'maxCombo': 10, 'name': 'Optimize Music Classification Network', 'parameters': {'batch_size': {'type': 'discrete', 'values': [32, 64]}, 'epochs': {'type': 'discrete', 'values': [150]}, 'first_layer_dropout_rate': {'type': 'discrete', 'values': [0.4, 0.5, 0.6, 0.7, 0.8]}, 'first_layer_units': {'type': 'discrete', 'values': [450, 500, 550, 600, 650, 700, 750, 800, 850, 900, 950, 1000]}, 'second_layer_dropout_rate': {'type': 'discrete', 'values': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]}, 'second_layer_units': {'type': 'discrete', 'values': [300, 400, 450, 500, 550, 600, 650, 700, 750, 800]}, 'third_layer_dropout_rate': {'type': 'discrete', 'values': [0.1, 0.2, 0.3, 0.4]}, 'third_layer_units': {'type': 'discrete', 'values': [50, 75, 100, 200, 300, 400, 450]}}, 'predictor': None, 'spec': {'gridSize': 10, 'maxCombo': 10, 'metric': 'loss', 'minSampleSize': 100, 'objective': 'minimize', 'retryAssignLimit': 0, 'retryLimit': 1000}, 'startTime': 26990864014, 'state': {'mode': None, 'seed': None, 'sequence': [], 'sequence_i': 0, 'sequence_pid': None, 'sequence_retry': 0, 'sequence_retry_count': 0}, 'status': 'running', 'suggestion_count': 0, 'trials': 1, 'version': '2.0.1'}\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/37ce9e0096114a6dad158e8aa8ef3683\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     copy      : True\n",
      "COMET INFO:     with_mean : True\n",
      "COMET INFO:     with_std  : True\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/a0bee2ad8b5a4d21980761c1ef845710\n",
      "\n",
      "COMET WARNING: 'epochs' passed to log_params converted to an empty maping; ignoring\n",
      "COMET INFO: Ignoring automatic log_parameter('verbose') because 'keras:verbose' is in COMET_LOGGING_PARAMETERS_IGNORE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ignoring tensorflow summary log of metrics because of keras; set `comet_ml.loggers.tensorboard_logger.LOG_METRICS = True` to override\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 15s 14ms/step - loss: 0.4412 - accuracy: 0.8647 - val_loss: 0.2370 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 9s 10ms/step - loss: 0.3037 - accuracy: 0.9071 - val_loss: 0.1983 - val_accuracy: 0.9398 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2559 - accuracy: 0.9211 - val_loss: 0.1824 - val_accuracy: 0.9458 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 7s 8ms/step - loss: 0.2268 - accuracy: 0.9291 - val_loss: 0.1698 - val_accuracy: 0.9489 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2046 - accuracy: 0.9346 - val_loss: 0.1513 - val_accuracy: 0.9548 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1870 - accuracy: 0.9399 - val_loss: 0.1468 - val_accuracy: 0.9543 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1805 - accuracy: 0.9421 - val_loss: 0.1439 - val_accuracy: 0.9569 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1619 - accuracy: 0.9495 - val_loss: 0.1315 - val_accuracy: 0.9614 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 6s 7ms/step - loss: 0.1529 - accuracy: 0.9514 - val_loss: 0.1284 - val_accuracy: 0.9617 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 7s 8ms/step - loss: 0.1433 - accuracy: 0.9547 - val_loss: 0.1282 - val_accuracy: 0.9614 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.1398 - accuracy: 0.9555 - val_loss: 0.1177 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1314 - accuracy: 0.9570 - val_loss: 0.1162 - val_accuracy: 0.9649 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.1227 - accuracy: 0.9600 - val_loss: 0.1261 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1171 - accuracy: 0.9621 - val_loss: 0.1156 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1138 - accuracy: 0.9623 - val_loss: 0.1146 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 6s 7ms/step - loss: 0.1111 - accuracy: 0.9634 - val_loss: 0.1153 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 9s 10ms/step - loss: 0.1000 - accuracy: 0.9665 - val_loss: 0.1087 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 6s 7ms/step - loss: 0.1000 - accuracy: 0.9676 - val_loss: 0.1183 - val_accuracy: 0.9672 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1030 - accuracy: 0.9664 - val_loss: 0.1165 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "877/880 [============================>.] - ETA: 0s - loss: 0.0913 - accuracy: 0.9694\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0911 - accuracy: 0.9694 - val_loss: 0.1144 - val_accuracy: 0.9686 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0847 - accuracy: 0.9720 - val_loss: 0.1055 - val_accuracy: 0.9715 - lr: 7.0000e-04\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0758 - accuracy: 0.9751 - val_loss: 0.1045 - val_accuracy: 0.9711 - lr: 7.0000e-04\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0761 - accuracy: 0.9748 - val_loss: 0.1076 - val_accuracy: 0.9712 - lr: 7.0000e-04\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0715 - accuracy: 0.9769 - val_loss: 0.1024 - val_accuracy: 0.9728 - lr: 7.0000e-04\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0737 - accuracy: 0.9753 - val_loss: 0.1062 - val_accuracy: 0.9723 - lr: 7.0000e-04\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0691 - accuracy: 0.9767 - val_loss: 0.1029 - val_accuracy: 0.9737 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "877/880 [============================>.] - ETA: 0s - loss: 0.0677 - accuracy: 0.9777\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.1091 - val_accuracy: 0.9722 - lr: 7.0000e-04\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.1033 - val_accuracy: 0.9729 - lr: 4.9000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0577 - accuracy: 0.9807 - val_loss: 0.1023 - val_accuracy: 0.9739 - lr: 4.9000e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0559 - accuracy: 0.9811 - val_loss: 0.1067 - val_accuracy: 0.9734 - lr: 4.9000e-04\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0519 - accuracy: 0.9822 - val_loss: 0.1057 - val_accuracy: 0.9732 - lr: 4.9000e-04\n",
      "Epoch 32/150\n",
      "872/880 [============================>.] - ETA: 0s - loss: 0.0537 - accuracy: 0.9824\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0534 - accuracy: 0.9825 - val_loss: 0.1041 - val_accuracy: 0.9745 - lr: 4.9000e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0494 - accuracy: 0.9829 - val_loss: 0.1007 - val_accuracy: 0.9755 - lr: 3.4300e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0467 - accuracy: 0.9838 - val_loss: 0.1000 - val_accuracy: 0.9745 - lr: 3.4300e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0450 - accuracy: 0.9851 - val_loss: 0.1031 - val_accuracy: 0.9741 - lr: 3.4300e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0444 - accuracy: 0.9848 - val_loss: 0.1034 - val_accuracy: 0.9746 - lr: 3.4300e-04\n",
      "Epoch 37/150\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.0402 - accuracy: 0.9859\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0402 - accuracy: 0.9859 - val_loss: 0.1057 - val_accuracy: 0.9732 - lr: 3.4300e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0439 - accuracy: 0.9845 - val_loss: 0.1000 - val_accuracy: 0.9756 - lr: 2.4010e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0399 - accuracy: 0.9866 - val_loss: 0.1024 - val_accuracy: 0.9753 - lr: 2.4010e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0403 - accuracy: 0.9864 - val_loss: 0.1015 - val_accuracy: 0.9750 - lr: 2.4010e-04\n",
      "Epoch 41/150\n",
      "872/880 [============================>.] - ETA: 0s - loss: 0.0395 - accuracy: 0.9865\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0396 - accuracy: 0.9865 - val_loss: 0.1010 - val_accuracy: 0.9758 - lr: 2.4010e-04\n",
      "Epoch 42/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0385 - accuracy: 0.9865 - val_loss: 0.1014 - val_accuracy: 0.9755 - lr: 1.6807e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0392 - accuracy: 0.9862 - val_loss: 0.1000 - val_accuracy: 0.9755 - lr: 1.6807e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0355 - accuracy: 0.9880 - val_loss: 0.1002 - val_accuracy: 0.9761 - lr: 1.6807e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0356 - accuracy: 0.9875 - val_loss: 0.1009 - val_accuracy: 0.9756 - lr: 1.6807e-04\n",
      "Epoch 46/150\n",
      "874/880 [============================>.] - ETA: 0s - loss: 0.0340 - accuracy: 0.9887\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 0.1025 - val_accuracy: 0.9744 - lr: 1.6807e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0340 - accuracy: 0.9880 - val_loss: 0.1010 - val_accuracy: 0.9755 - lr: 1.1765e-04\n",
      "Epoch 48/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.1028 - val_accuracy: 0.9758 - lr: 1.1765e-04\n",
      "Epoch 49/150\n",
      "876/880 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9875\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0354 - accuracy: 0.9875 - val_loss: 0.1021 - val_accuracy: 0.9755 - lr: 1.1765e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0315 - accuracy: 0.9889 - val_loss: 0.1034 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 51/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.1031 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0320 - accuracy: 0.9888 - val_loss: 0.1032 - val_accuracy: 0.9762 - lr: 1.0000e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0297 - accuracy: 0.9900 - val_loss: 0.1027 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 1/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.4416 - accuracy: 0.8640 - val_loss: 0.2599 - val_accuracy: 0.9183 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.3004 - accuracy: 0.9077 - val_loss: 0.2016 - val_accuracy: 0.9403 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2576 - accuracy: 0.9207 - val_loss: 0.1739 - val_accuracy: 0.9464 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2256 - accuracy: 0.9308 - val_loss: 0.1601 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.2082 - accuracy: 0.9355 - val_loss: 0.1552 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1827 - accuracy: 0.9416 - val_loss: 0.1473 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1787 - accuracy: 0.9439 - val_loss: 0.1344 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1641 - accuracy: 0.9498 - val_loss: 0.1307 - val_accuracy: 0.9598 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1529 - accuracy: 0.9512 - val_loss: 0.1337 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1480 - accuracy: 0.9533 - val_loss: 0.1305 - val_accuracy: 0.9621 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1353 - accuracy: 0.9561 - val_loss: 0.1256 - val_accuracy: 0.9636 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1314 - accuracy: 0.9582 - val_loss: 0.1234 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 7s 8ms/step - loss: 0.1245 - accuracy: 0.9593 - val_loss: 0.1186 - val_accuracy: 0.9664 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 6s 6ms/step - loss: 0.1152 - accuracy: 0.9634 - val_loss: 0.1163 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1131 - accuracy: 0.9628 - val_loss: 0.1112 - val_accuracy: 0.9693 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.1102 - accuracy: 0.9639 - val_loss: 0.1113 - val_accuracy: 0.9689 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1020 - accuracy: 0.9681 - val_loss: 0.1098 - val_accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0987 - accuracy: 0.9680 - val_loss: 0.1110 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0977 - accuracy: 0.9665 - val_loss: 0.1088 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0930 - accuracy: 0.9688 - val_loss: 0.1156 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0958 - accuracy: 0.9679 - val_loss: 0.1104 - val_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "871/880 [============================>.] - ETA: 0s - loss: 0.0854 - accuracy: 0.9717\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0857 - accuracy: 0.9716 - val_loss: 0.1088 - val_accuracy: 0.9706 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0774 - accuracy: 0.9740 - val_loss: 0.1033 - val_accuracy: 0.9721 - lr: 7.0000e-04\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0722 - accuracy: 0.9763 - val_loss: 0.1042 - val_accuracy: 0.9728 - lr: 7.0000e-04\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0703 - accuracy: 0.9765 - val_loss: 0.1013 - val_accuracy: 0.9731 - lr: 7.0000e-04\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0662 - accuracy: 0.9780 - val_loss: 0.1051 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.0670 - accuracy: 0.9779 - val_loss: 0.1045 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 28/150\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.0676 - accuracy: 0.9779\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.1040 - val_accuracy: 0.9747 - lr: 7.0000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0541 - accuracy: 0.9814 - val_loss: 0.1016 - val_accuracy: 0.9748 - lr: 4.9000e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 6s 6ms/step - loss: 0.0545 - accuracy: 0.9821 - val_loss: 0.1035 - val_accuracy: 0.9750 - lr: 4.9000e-04\n",
      "Epoch 31/150\n",
      "871/880 [============================>.] - ETA: 0s - loss: 0.0526 - accuracy: 0.9813\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0528 - accuracy: 0.9813 - val_loss: 0.1051 - val_accuracy: 0.9745 - lr: 4.9000e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.0476 - accuracy: 0.9838 - val_loss: 0.1014 - val_accuracy: 0.9749 - lr: 3.4300e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 7s 7ms/step - loss: 0.0499 - accuracy: 0.9828 - val_loss: 0.1005 - val_accuracy: 0.9747 - lr: 3.4300e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0495 - accuracy: 0.9825 - val_loss: 0.0988 - val_accuracy: 0.9754 - lr: 3.4300e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0459 - accuracy: 0.9842 - val_loss: 0.1006 - val_accuracy: 0.9764 - lr: 3.4300e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0445 - accuracy: 0.9853 - val_loss: 0.1018 - val_accuracy: 0.9751 - lr: 3.4300e-04\n",
      "Epoch 37/150\n",
      "871/880 [============================>.] - ETA: 0s - loss: 0.0437 - accuracy: 0.9854\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0437 - accuracy: 0.9854 - val_loss: 0.1027 - val_accuracy: 0.9751 - lr: 3.4300e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0407 - accuracy: 0.9863 - val_loss: 0.1006 - val_accuracy: 0.9763 - lr: 2.4010e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0422 - accuracy: 0.9860 - val_loss: 0.1017 - val_accuracy: 0.9761 - lr: 2.4010e-04\n",
      "Epoch 40/150\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.0382 - accuracy: 0.9870\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0382 - accuracy: 0.9870 - val_loss: 0.1022 - val_accuracy: 0.9759 - lr: 2.4010e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0398 - accuracy: 0.9856 - val_loss: 0.1040 - val_accuracy: 0.9762 - lr: 1.6807e-04\n",
      "Epoch 42/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0358 - accuracy: 0.9885 - val_loss: 0.1025 - val_accuracy: 0.9754 - lr: 1.6807e-04\n",
      "Epoch 43/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.0357 - accuracy: 0.9877\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.1004 - val_accuracy: 0.9758 - lr: 1.6807e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0344 - accuracy: 0.9882 - val_loss: 0.1005 - val_accuracy: 0.9762 - lr: 1.1765e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.0988 - accuracy: 0.9754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.09876728057861328, 0.9753968119621277]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/a0bee2ad8b5a4d21980761c1ef845710\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [97]                  : (0.8639658689498901, 0.9900497794151306)\n",
      "COMET INFO:     batch_accuracy [8536]          : (0.03125, 1.0)\n",
      "COMET INFO:     batch_loss [8536]              : (0.00022866768995299935, 2.8641672134399414)\n",
      "COMET INFO:     epoch_duration [97]            : (3.42200000000048, 14.718999999999141)\n",
      "COMET INFO:     loss [97]                      : (0.02974042482674122, 0.4416247010231018)\n",
      "COMET INFO:     lr [97]                        : (9.999999747378752e-05, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [97]              : (0.9182539582252502, 0.9764069318771362)\n",
      "COMET INFO:     val_loss [97]                  : (0.09876728057861328, 0.2598975598812103)\n",
      "COMET INFO:     validate_batch_accuracy [4268] : (0.9127252101898193, 1.0)\n",
      "COMET INFO:     validate_batch_loss [4268]     : (0.001292512402869761, 0.33325663208961487)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 1\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.02974042482674122\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 32, \"epochs\": 150, \"first_layer_dropout_rate\": 0.5, \"first_layer_units\": 950, \"second_layer_dropout_rate\": 0.5, \"second_layer_units\": 600, \"third_layer_dropout_rate\": 0.2, \"third_layer_units\": 100}\n",
      "COMET INFO:     optimizer_pid          : 84bef2c6da935330af013d9d737149bb7a884bb9\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1384060\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 32\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.5\n",
      "COMET INFO:     first_layer_units         : 950\n",
      "COMET INFO:     second_layer_dropout_rate : 0.5\n",
      "COMET INFO:     second_layer_units        : 600\n",
      "COMET INFO:     steps                     : 880\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.2\n",
      "COMET INFO:     third_layer_units         : 100\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading metrics, params, and assets to Comet before program termination (may take several seconds)\n",
      "COMET INFO: The Python SDK has 3600 seconds to finish before aborting...\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/f39bab9bb091441ba5e35eab873d0126\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  6/880 [..............................] - ETA: 10s - loss: 2.3727 - accuracy: 0.2396 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0050s vs `on_train_batch_end` time: 0.0063s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 4s 4ms/step - loss: 0.5389 - accuracy: 0.8344 - val_loss: 0.2677 - val_accuracy: 0.9177 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3733 - accuracy: 0.8859 - val_loss: 0.2223 - val_accuracy: 0.9340 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3149 - accuracy: 0.9019 - val_loss: 0.2010 - val_accuracy: 0.9408 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2908 - accuracy: 0.9096 - val_loss: 0.1846 - val_accuracy: 0.9445 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2699 - accuracy: 0.9159 - val_loss: 0.1751 - val_accuracy: 0.9471 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.2511 - accuracy: 0.9213 - val_loss: 0.1686 - val_accuracy: 0.9488 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2395 - accuracy: 0.9244 - val_loss: 0.1547 - val_accuracy: 0.9532 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2249 - accuracy: 0.9305 - val_loss: 0.1529 - val_accuracy: 0.9529 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2211 - accuracy: 0.9311 - val_loss: 0.1445 - val_accuracy: 0.9558 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2093 - accuracy: 0.9347 - val_loss: 0.1454 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1998 - accuracy: 0.9373 - val_loss: 0.1363 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1937 - accuracy: 0.9395 - val_loss: 0.1362 - val_accuracy: 0.9576 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1866 - accuracy: 0.9408 - val_loss: 0.1377 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1753 - accuracy: 0.9426 - val_loss: 0.1307 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 6s 7ms/step - loss: 0.1725 - accuracy: 0.9452 - val_loss: 0.1282 - val_accuracy: 0.9607 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 6s 7ms/step - loss: 0.1729 - accuracy: 0.9437 - val_loss: 0.1221 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1678 - accuracy: 0.9463 - val_loss: 0.1256 - val_accuracy: 0.9648 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1591 - accuracy: 0.9494 - val_loss: 0.1224 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1494 - accuracy: 0.9517 - val_loss: 0.1217 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1531 - accuracy: 0.9511 - val_loss: 0.1233 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1553 - accuracy: 0.9505 - val_loss: 0.1145 - val_accuracy: 0.9672 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1476 - accuracy: 0.9505 - val_loss: 0.1189 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1424 - accuracy: 0.9531 - val_loss: 0.1155 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "872/880 [============================>.] - ETA: 0s - loss: 0.1417 - accuracy: 0.9537\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1415 - accuracy: 0.9537 - val_loss: 0.1170 - val_accuracy: 0.9674 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1284 - accuracy: 0.9590 - val_loss: 0.1125 - val_accuracy: 0.9676 - lr: 7.0000e-04\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1249 - accuracy: 0.9600 - val_loss: 0.1090 - val_accuracy: 0.9689 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1202 - accuracy: 0.9611 - val_loss: 0.1106 - val_accuracy: 0.9689 - lr: 7.0000e-04\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1170 - accuracy: 0.9616 - val_loss: 0.1100 - val_accuracy: 0.9685 - lr: 7.0000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1139 - accuracy: 0.9621 - val_loss: 0.1064 - val_accuracy: 0.9702 - lr: 7.0000e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1136 - accuracy: 0.9633 - val_loss: 0.1078 - val_accuracy: 0.9694 - lr: 7.0000e-04\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1130 - accuracy: 0.9635 - val_loss: 0.1021 - val_accuracy: 0.9708 - lr: 7.0000e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1128 - accuracy: 0.9641 - val_loss: 0.1101 - val_accuracy: 0.9694 - lr: 7.0000e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1103 - accuracy: 0.9636 - val_loss: 0.1057 - val_accuracy: 0.9704 - lr: 7.0000e-04\n",
      "Epoch 34/150\n",
      "873/880 [============================>.] - ETA: 0s - loss: 0.1060 - accuracy: 0.9652\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1057 - accuracy: 0.9654 - val_loss: 0.1074 - val_accuracy: 0.9694 - lr: 7.0000e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1038 - accuracy: 0.9657 - val_loss: 0.1055 - val_accuracy: 0.9693 - lr: 4.9000e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1022 - accuracy: 0.9663 - val_loss: 0.1055 - val_accuracy: 0.9705 - lr: 4.9000e-04\n",
      "Epoch 37/150\n",
      "878/880 [============================>.] - ETA: 0s - loss: 0.0969 - accuracy: 0.9670\n",
      "Epoch 00037: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0969 - accuracy: 0.9671 - val_loss: 0.1067 - val_accuracy: 0.9709 - lr: 4.9000e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0935 - accuracy: 0.9686 - val_loss: 0.1013 - val_accuracy: 0.9712 - lr: 3.4300e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0910 - accuracy: 0.9696 - val_loss: 0.1009 - val_accuracy: 0.9716 - lr: 3.4300e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0865 - accuracy: 0.9712 - val_loss: 0.1018 - val_accuracy: 0.9726 - lr: 3.4300e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0870 - accuracy: 0.9714 - val_loss: 0.1006 - val_accuracy: 0.9731 - lr: 3.4300e-04\n",
      "Epoch 42/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0828 - accuracy: 0.9726 - val_loss: 0.1022 - val_accuracy: 0.9712 - lr: 3.4300e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0893 - accuracy: 0.9714 - val_loss: 0.1005 - val_accuracy: 0.9719 - lr: 3.4300e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0843 - accuracy: 0.9727 - val_loss: 0.1005 - val_accuracy: 0.9727 - lr: 3.4300e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0830 - accuracy: 0.9720 - val_loss: 0.1005 - val_accuracy: 0.9717 - lr: 3.4300e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0814 - accuracy: 0.9728 - val_loss: 0.1024 - val_accuracy: 0.9724 - lr: 3.4300e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0825 - accuracy: 0.9735 - val_loss: 0.1026 - val_accuracy: 0.9729 - lr: 3.4300e-04\n",
      "Epoch 48/150\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.0817 - accuracy: 0.9727\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0817 - accuracy: 0.9726 - val_loss: 0.1031 - val_accuracy: 0.9719 - lr: 3.4300e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0777 - accuracy: 0.9737 - val_loss: 0.1006 - val_accuracy: 0.9727 - lr: 2.4010e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.0737 - accuracy: 0.9757 - val_loss: 0.1013 - val_accuracy: 0.9727 - lr: 2.4010e-04\n",
      "Epoch 51/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0768 - accuracy: 0.9742 - val_loss: 0.0996 - val_accuracy: 0.9736 - lr: 2.4010e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0775 - accuracy: 0.9732 - val_loss: 0.1006 - val_accuracy: 0.9729 - lr: 2.4010e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0770 - accuracy: 0.9742 - val_loss: 0.1003 - val_accuracy: 0.9735 - lr: 2.4010e-04\n",
      "Epoch 54/150\n",
      "874/880 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9744\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0758 - accuracy: 0.9744 - val_loss: 0.1005 - val_accuracy: 0.9731 - lr: 2.4010e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0730 - accuracy: 0.9756 - val_loss: 0.0986 - val_accuracy: 0.9737 - lr: 1.6807e-04\n",
      "Epoch 56/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0708 - accuracy: 0.9771 - val_loss: 0.1007 - val_accuracy: 0.9727 - lr: 1.6807e-04\n",
      "Epoch 57/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.0706 - accuracy: 0.9753 - val_loss: 0.0990 - val_accuracy: 0.9734 - lr: 1.6807e-04\n",
      "Epoch 58/150\n",
      "872/880 [============================>.] - ETA: 0s - loss: 0.0696 - accuracy: 0.9771\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0698 - accuracy: 0.9770 - val_loss: 0.1005 - val_accuracy: 0.9732 - lr: 1.6807e-04\n",
      "Epoch 59/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0692 - accuracy: 0.9768 - val_loss: 0.0997 - val_accuracy: 0.9734 - lr: 1.1765e-04\n",
      "Epoch 60/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0671 - accuracy: 0.9769 - val_loss: 0.1005 - val_accuracy: 0.9734 - lr: 1.1765e-04\n",
      "Epoch 61/150\n",
      "880/880 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9776\n",
      "Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0656 - accuracy: 0.9776 - val_loss: 0.0995 - val_accuracy: 0.9734 - lr: 1.1765e-04\n",
      "Epoch 62/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0681 - accuracy: 0.9762 - val_loss: 0.1003 - val_accuracy: 0.9729 - lr: 1.0000e-04\n",
      "Epoch 63/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0653 - accuracy: 0.9786 - val_loss: 0.1004 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 64/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0647 - accuracy: 0.9785 - val_loss: 0.1005 - val_accuracy: 0.9742 - lr: 1.0000e-04\n",
      "Epoch 65/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0661 - accuracy: 0.9787 - val_loss: 0.1020 - val_accuracy: 0.9732 - lr: 1.0000e-04\n",
      "Epoch 1/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.5421 - accuracy: 0.8334 - val_loss: 0.2766 - val_accuracy: 0.9151 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.3704 - accuracy: 0.8866 - val_loss: 0.2385 - val_accuracy: 0.9268 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.3163 - accuracy: 0.9012 - val_loss: 0.2069 - val_accuracy: 0.9372 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2887 - accuracy: 0.9104 - val_loss: 0.1915 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2666 - accuracy: 0.9152 - val_loss: 0.1790 - val_accuracy: 0.9465 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2591 - accuracy: 0.9172 - val_loss: 0.1641 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2412 - accuracy: 0.9241 - val_loss: 0.1698 - val_accuracy: 0.9482 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2271 - accuracy: 0.9285 - val_loss: 0.1595 - val_accuracy: 0.9517 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2102 - accuracy: 0.9334 - val_loss: 0.1446 - val_accuracy: 0.9558 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2102 - accuracy: 0.9356 - val_loss: 0.1446 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2020 - accuracy: 0.9350 - val_loss: 0.1393 - val_accuracy: 0.9587 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1884 - accuracy: 0.9409 - val_loss: 0.1467 - val_accuracy: 0.9569 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1882 - accuracy: 0.9417 - val_loss: 0.1350 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1790 - accuracy: 0.9428 - val_loss: 0.1451 - val_accuracy: 0.9561 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1747 - accuracy: 0.9442 - val_loss: 0.1261 - val_accuracy: 0.9627 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.1703 - accuracy: 0.9464 - val_loss: 0.1313 - val_accuracy: 0.9608 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1640 - accuracy: 0.9482 - val_loss: 0.1260 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1603 - accuracy: 0.9477 - val_loss: 0.1246 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1577 - accuracy: 0.9500 - val_loss: 0.1204 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1521 - accuracy: 0.9517 - val_loss: 0.1230 - val_accuracy: 0.9651 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1476 - accuracy: 0.9503 - val_loss: 0.1220 - val_accuracy: 0.9655 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1416 - accuracy: 0.9546 - val_loss: 0.1195 - val_accuracy: 0.9647 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1448 - accuracy: 0.9544 - val_loss: 0.1144 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1395 - accuracy: 0.9549 - val_loss: 0.1171 - val_accuracy: 0.9641 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1402 - accuracy: 0.9539 - val_loss: 0.1204 - val_accuracy: 0.9649 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1347 - accuracy: 0.9566 - val_loss: 0.1119 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1310 - accuracy: 0.9567 - val_loss: 0.1149 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1318 - accuracy: 0.9571 - val_loss: 0.1104 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1283 - accuracy: 0.9589 - val_loss: 0.1060 - val_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1197 - accuracy: 0.9608 - val_loss: 0.1118 - val_accuracy: 0.9677 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1197 - accuracy: 0.9622 - val_loss: 0.1089 - val_accuracy: 0.9687 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.1197 - accuracy: 0.9610\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1196 - accuracy: 0.9609 - val_loss: 0.1099 - val_accuracy: 0.9694 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1120 - accuracy: 0.9646 - val_loss: 0.1109 - val_accuracy: 0.9693 - lr: 7.0000e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1120 - accuracy: 0.9643 - val_loss: 0.1070 - val_accuracy: 0.9700 - lr: 7.0000e-04\n",
      "Epoch 35/150\n",
      "874/880 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9674\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1015 - accuracy: 0.9673 - val_loss: 0.1077 - val_accuracy: 0.9703 - lr: 7.0000e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0977 - accuracy: 0.9666 - val_loss: 0.1044 - val_accuracy: 0.9713 - lr: 4.9000e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0958 - accuracy: 0.9690 - val_loss: 0.1019 - val_accuracy: 0.9722 - lr: 4.9000e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0923 - accuracy: 0.9689 - val_loss: 0.1011 - val_accuracy: 0.9726 - lr: 4.9000e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0923 - accuracy: 0.9704 - val_loss: 0.0988 - val_accuracy: 0.9724 - lr: 4.9000e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0953 - accuracy: 0.9695 - val_loss: 0.0993 - val_accuracy: 0.9724 - lr: 4.9000e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0842 - accuracy: 0.9725 - val_loss: 0.1020 - val_accuracy: 0.9720 - lr: 4.9000e-04\n",
      "Epoch 42/150\n",
      "871/880 [============================>.] - ETA: 0s - loss: 0.0883 - accuracy: 0.9697\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0888 - accuracy: 0.9694 - val_loss: 0.1020 - val_accuracy: 0.9722 - lr: 4.9000e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0800 - accuracy: 0.9731 - val_loss: 0.1004 - val_accuracy: 0.9718 - lr: 3.4300e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0838 - accuracy: 0.9721 - val_loss: 0.0987 - val_accuracy: 0.9724 - lr: 3.4300e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0804 - accuracy: 0.9734 - val_loss: 0.0984 - val_accuracy: 0.9724 - lr: 3.4300e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0803 - accuracy: 0.9722 - val_loss: 0.1009 - val_accuracy: 0.9732 - lr: 3.4300e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0768 - accuracy: 0.9738 - val_loss: 0.1002 - val_accuracy: 0.9734 - lr: 3.4300e-04\n",
      "Epoch 48/150\n",
      "871/880 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.9731\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0791 - accuracy: 0.9731 - val_loss: 0.0995 - val_accuracy: 0.9732 - lr: 3.4300e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0761 - accuracy: 0.9754 - val_loss: 0.0992 - val_accuracy: 0.9732 - lr: 2.4010e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0699 - accuracy: 0.9762 - val_loss: 0.1000 - val_accuracy: 0.9734 - lr: 2.4010e-04\n",
      "Epoch 51/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.0740 - accuracy: 0.9760\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0739 - accuracy: 0.9759 - val_loss: 0.1006 - val_accuracy: 0.9727 - lr: 2.4010e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0697 - accuracy: 0.9762 - val_loss: 0.0989 - val_accuracy: 0.9735 - lr: 1.6807e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0706 - accuracy: 0.9758 - val_loss: 0.0992 - val_accuracy: 0.9728 - lr: 1.6807e-04\n",
      "Epoch 54/150\n",
      "876/880 [============================>.] - ETA: 0s - loss: 0.0680 - accuracy: 0.9777\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0680 - accuracy: 0.9778 - val_loss: 0.0992 - val_accuracy: 0.9733 - lr: 1.6807e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0696 - accuracy: 0.9760 - val_loss: 0.0997 - val_accuracy: 0.9733 - lr: 1.1765e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.0984 - accuracy: 0.9724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.0983932763338089, 0.9724386930465698]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/f39bab9bb091441ba5e35eab873d0126\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [120]                 : (0.8334399461746216, 0.9787490963935852)\n",
      "COMET INFO:     batch_accuracy [10560]         : (0.09375, 1.0)\n",
      "COMET INFO:     batch_loss [10560]             : (0.002815855201333761, 2.962376356124878)\n",
      "COMET INFO:     epoch_duration [120]           : (3.4210000000002765, 6.031999999999243)\n",
      "COMET INFO:     loss [120]                     : (0.06469569355249405, 0.5421146750450134)\n",
      "COMET INFO:     lr [120]                       : (9.999999747378752e-05, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [120]             : (0.9150793552398682, 0.9742424488067627)\n",
      "COMET INFO:     val_loss [120]                 : (0.0983932763338089, 0.2765948474407196)\n",
      "COMET INFO:     validate_batch_accuracy [5280] : (0.9054054021835327, 1.0)\n",
      "COMET INFO:     validate_batch_loss [5280]     : (0.005506718065589666, 0.35445988178253174)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 2\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.06469569355249405\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 32, \"epochs\": 150, \"first_layer_dropout_rate\": 0.7, \"first_layer_units\": 850, \"second_layer_dropout_rate\": 0.6, \"second_layer_units\": 600, \"third_layer_dropout_rate\": 0.2, \"third_layer_units\": 300}\n",
      "COMET INFO:     optimizer_pid          : 4077c4838a35a03cca8f9bc761bf5582c56336a2\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1368160\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 32\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.7\n",
      "COMET INFO:     first_layer_units         : 850\n",
      "COMET INFO:     second_layer_dropout_rate : 0.6\n",
      "COMET INFO:     second_layer_units        : 600\n",
      "COMET INFO:     steps                     : 880\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.2\n",
      "COMET INFO:     third_layer_units         : 300\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/95ab73206cbf4c5db672547efd4c476c\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  6/880 [..............................] - ETA: 10s - loss: 2.3822 - accuracy: 0.2292 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0052s vs `on_train_batch_end` time: 0.0063s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 4s 4ms/step - loss: 0.5292 - accuracy: 0.8366 - val_loss: 0.2684 - val_accuracy: 0.9180 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3846 - accuracy: 0.8813 - val_loss: 0.2255 - val_accuracy: 0.9333 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3386 - accuracy: 0.8945 - val_loss: 0.2067 - val_accuracy: 0.9373 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3095 - accuracy: 0.9052 - val_loss: 0.1862 - val_accuracy: 0.9409 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2896 - accuracy: 0.9093 - val_loss: 0.1767 - val_accuracy: 0.9465 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2692 - accuracy: 0.9151 - val_loss: 0.1663 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2497 - accuracy: 0.9236 - val_loss: 0.1657 - val_accuracy: 0.9491 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2438 - accuracy: 0.9252 - val_loss: 0.1548 - val_accuracy: 0.9542 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2281 - accuracy: 0.9274 - val_loss: 0.1460 - val_accuracy: 0.9543 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2240 - accuracy: 0.9288 - val_loss: 0.1451 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2135 - accuracy: 0.9316 - val_loss: 0.1380 - val_accuracy: 0.9572 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2016 - accuracy: 0.9367 - val_loss: 0.1275 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1941 - accuracy: 0.9383 - val_loss: 0.1313 - val_accuracy: 0.9613 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1933 - accuracy: 0.9382 - val_loss: 0.1237 - val_accuracy: 0.9618 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1851 - accuracy: 0.9429 - val_loss: 0.1214 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1803 - accuracy: 0.9431 - val_loss: 0.1189 - val_accuracy: 0.9646 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1743 - accuracy: 0.9444 - val_loss: 0.1191 - val_accuracy: 0.9641 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1698 - accuracy: 0.9452 - val_loss: 0.1142 - val_accuracy: 0.9660 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1613 - accuracy: 0.9484 - val_loss: 0.1106 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1561 - accuracy: 0.9501 - val_loss: 0.1078 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1607 - accuracy: 0.9479 - val_loss: 0.1078 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1546 - accuracy: 0.9485 - val_loss: 0.1048 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1499 - accuracy: 0.9507 - val_loss: 0.1056 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1432 - accuracy: 0.9538 - val_loss: 0.1057 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "870/880 [============================>.] - ETA: 0s - loss: 0.1405 - accuracy: 0.9551\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1400 - accuracy: 0.9552 - val_loss: 0.1077 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1343 - accuracy: 0.9568 - val_loss: 0.0985 - val_accuracy: 0.9705 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1287 - accuracy: 0.9588 - val_loss: 0.1010 - val_accuracy: 0.9694 - lr: 7.0000e-04\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1251 - accuracy: 0.9592 - val_loss: 0.0962 - val_accuracy: 0.9695 - lr: 7.0000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1204 - accuracy: 0.9613 - val_loss: 0.0952 - val_accuracy: 0.9714 - lr: 7.0000e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1224 - accuracy: 0.9602 - val_loss: 0.0932 - val_accuracy: 0.9730 - lr: 7.0000e-04\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1169 - accuracy: 0.9613 - val_loss: 0.0956 - val_accuracy: 0.9721 - lr: 7.0000e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.1162 - accuracy: 0.9629 - val_loss: 0.0938 - val_accuracy: 0.9713 - lr: 7.0000e-04\n",
      "Epoch 33/150\n",
      "872/880 [============================>.] - ETA: 0s - loss: 0.1161 - accuracy: 0.9629\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1163 - accuracy: 0.9628 - val_loss: 0.0932 - val_accuracy: 0.9719 - lr: 7.0000e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1056 - accuracy: 0.9651 - val_loss: 0.0929 - val_accuracy: 0.9723 - lr: 4.9000e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1051 - accuracy: 0.9662 - val_loss: 0.0912 - val_accuracy: 0.9722 - lr: 4.9000e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1068 - accuracy: 0.9657 - val_loss: 0.0895 - val_accuracy: 0.9731 - lr: 4.9000e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1015 - accuracy: 0.9675 - val_loss: 0.0913 - val_accuracy: 0.9727 - lr: 4.9000e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1029 - accuracy: 0.9665 - val_loss: 0.0914 - val_accuracy: 0.9737 - lr: 4.9000e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0987 - accuracy: 0.9686 - val_loss: 0.0888 - val_accuracy: 0.9725 - lr: 4.9000e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0964 - accuracy: 0.9672 - val_loss: 0.0894 - val_accuracy: 0.9732 - lr: 4.9000e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0942 - accuracy: 0.9699 - val_loss: 0.0908 - val_accuracy: 0.9733 - lr: 4.9000e-04\n",
      "Epoch 42/150\n",
      "875/880 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9680\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0955 - accuracy: 0.9681 - val_loss: 0.0900 - val_accuracy: 0.9738 - lr: 4.9000e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0926 - accuracy: 0.9698 - val_loss: 0.0870 - val_accuracy: 0.9751 - lr: 3.4300e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0890 - accuracy: 0.9694 - val_loss: 0.0883 - val_accuracy: 0.9743 - lr: 3.4300e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0906 - accuracy: 0.9701 - val_loss: 0.0864 - val_accuracy: 0.9747 - lr: 3.4300e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0868 - accuracy: 0.9713 - val_loss: 0.0879 - val_accuracy: 0.9742 - lr: 3.4300e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0860 - accuracy: 0.9711 - val_loss: 0.0873 - val_accuracy: 0.9755 - lr: 3.4300e-04\n",
      "Epoch 48/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0846 - accuracy: 0.9726 - val_loss: 0.0864 - val_accuracy: 0.9750 - lr: 3.4300e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0826 - accuracy: 0.9729 - val_loss: 0.0861 - val_accuracy: 0.9750 - lr: 3.4300e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0771 - accuracy: 0.9734 - val_loss: 0.0859 - val_accuracy: 0.9762 - lr: 3.4300e-04\n",
      "Epoch 51/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0856 - accuracy: 0.9716 - val_loss: 0.0873 - val_accuracy: 0.9755 - lr: 3.4300e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0857 - accuracy: 0.9716 - val_loss: 0.0863 - val_accuracy: 0.9753 - lr: 3.4300e-04\n",
      "Epoch 53/150\n",
      "872/880 [============================>.] - ETA: 0s - loss: 0.0774 - accuracy: 0.9732\n",
      "Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0770 - accuracy: 0.9733 - val_loss: 0.0870 - val_accuracy: 0.9763 - lr: 3.4300e-04\n",
      "Epoch 54/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0758 - accuracy: 0.9737 - val_loss: 0.0851 - val_accuracy: 0.9756 - lr: 2.4010e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0772 - accuracy: 0.9734 - val_loss: 0.0859 - val_accuracy: 0.9760 - lr: 2.4010e-04\n",
      "Epoch 56/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0766 - accuracy: 0.9740 - val_loss: 0.0848 - val_accuracy: 0.9758 - lr: 2.4010e-04\n",
      "Epoch 57/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0780 - accuracy: 0.9740 - val_loss: 0.0859 - val_accuracy: 0.9749 - lr: 2.4010e-04\n",
      "Epoch 58/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0775 - accuracy: 0.9747 - val_loss: 0.0849 - val_accuracy: 0.9766 - lr: 2.4010e-04\n",
      "Epoch 59/150\n",
      "870/880 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9755\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0717 - accuracy: 0.9755 - val_loss: 0.0852 - val_accuracy: 0.9770 - lr: 2.4010e-04\n",
      "Epoch 60/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0743 - accuracy: 0.9749 - val_loss: 0.0843 - val_accuracy: 0.9768 - lr: 1.6807e-04\n",
      "Epoch 61/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0739 - accuracy: 0.9753 - val_loss: 0.0841 - val_accuracy: 0.9765 - lr: 1.6807e-04\n",
      "Epoch 62/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0707 - accuracy: 0.9760 - val_loss: 0.0852 - val_accuracy: 0.9766 - lr: 1.6807e-04\n",
      "Epoch 63/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0746 - accuracy: 0.9756 - val_loss: 0.0834 - val_accuracy: 0.9765 - lr: 1.6807e-04\n",
      "Epoch 64/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0716 - accuracy: 0.9758 - val_loss: 0.0833 - val_accuracy: 0.9761 - lr: 1.6807e-04\n",
      "Epoch 65/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0723 - accuracy: 0.9760 - val_loss: 0.0838 - val_accuracy: 0.9766 - lr: 1.6807e-04\n",
      "Epoch 66/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0704 - accuracy: 0.9763 - val_loss: 0.0827 - val_accuracy: 0.9771 - lr: 1.6807e-04\n",
      "Epoch 67/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0680 - accuracy: 0.9776 - val_loss: 0.0840 - val_accuracy: 0.9768 - lr: 1.6807e-04\n",
      "Epoch 68/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0674 - accuracy: 0.9774 - val_loss: 0.0821 - val_accuracy: 0.9764 - lr: 1.6807e-04\n",
      "Epoch 69/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0667 - accuracy: 0.9773 - val_loss: 0.0834 - val_accuracy: 0.9770 - lr: 1.6807e-04\n",
      "Epoch 70/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0664 - accuracy: 0.9774 - val_loss: 0.0835 - val_accuracy: 0.9764 - lr: 1.6807e-04\n",
      "Epoch 71/150\n",
      "865/880 [============================>.] - ETA: 0s - loss: 0.0638 - accuracy: 0.9792\n",
      "Epoch 00071: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0635 - accuracy: 0.9793 - val_loss: 0.0829 - val_accuracy: 0.9771 - lr: 1.6807e-04\n",
      "Epoch 72/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0682 - accuracy: 0.9767 - val_loss: 0.0824 - val_accuracy: 0.9768 - lr: 1.1765e-04\n",
      "Epoch 73/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.0822 - val_accuracy: 0.9770 - lr: 1.1765e-04\n",
      "Epoch 74/150\n",
      "868/880 [============================>.] - ETA: 0s - loss: 0.0639 - accuracy: 0.9788\n",
      "Epoch 00074: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0640 - accuracy: 0.9787 - val_loss: 0.0826 - val_accuracy: 0.9774 - lr: 1.1765e-04\n",
      "Epoch 75/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0661 - accuracy: 0.9775 - val_loss: 0.0825 - val_accuracy: 0.9765 - lr: 1.0000e-04\n",
      "Epoch 76/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0643 - accuracy: 0.9788 - val_loss: 0.0829 - val_accuracy: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 77/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0653 - accuracy: 0.9782 - val_loss: 0.0830 - val_accuracy: 0.9765 - lr: 1.0000e-04\n",
      "Epoch 78/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0634 - accuracy: 0.9785 - val_loss: 0.0832 - val_accuracy: 0.9767 - lr: 1.0000e-04\n",
      "Epoch 1/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.5359 - accuracy: 0.8326 - val_loss: 0.2740 - val_accuracy: 0.9157 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3787 - accuracy: 0.8817 - val_loss: 0.2298 - val_accuracy: 0.9315 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.3381 - accuracy: 0.8955 - val_loss: 0.2119 - val_accuracy: 0.9356 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.3105 - accuracy: 0.9035 - val_loss: 0.1922 - val_accuracy: 0.9419 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2831 - accuracy: 0.9111 - val_loss: 0.1877 - val_accuracy: 0.9432 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2760 - accuracy: 0.9139 - val_loss: 0.1747 - val_accuracy: 0.9462 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2568 - accuracy: 0.9197 - val_loss: 0.1667 - val_accuracy: 0.9496 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2347 - accuracy: 0.9279 - val_loss: 0.1542 - val_accuracy: 0.9534 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2384 - accuracy: 0.9244 - val_loss: 0.1527 - val_accuracy: 0.9525 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2173 - accuracy: 0.9323 - val_loss: 0.1460 - val_accuracy: 0.9557 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2172 - accuracy: 0.9302 - val_loss: 0.1353 - val_accuracy: 0.9576 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2065 - accuracy: 0.9340 - val_loss: 0.1314 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2000 - accuracy: 0.9352 - val_loss: 0.1318 - val_accuracy: 0.9584 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1925 - accuracy: 0.9402 - val_loss: 0.1266 - val_accuracy: 0.9605 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1860 - accuracy: 0.9401 - val_loss: 0.1226 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1804 - accuracy: 0.9418 - val_loss: 0.1232 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1782 - accuracy: 0.9415 - val_loss: 0.1193 - val_accuracy: 0.9641 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1677 - accuracy: 0.9467 - val_loss: 0.1134 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1697 - accuracy: 0.9462 - val_loss: 0.1097 - val_accuracy: 0.9674 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1551 - accuracy: 0.9507 - val_loss: 0.1113 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1558 - accuracy: 0.9491 - val_loss: 0.1104 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.1504 - accuracy: 0.9513 - val_loss: 0.1077 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1450 - accuracy: 0.9526 - val_loss: 0.1085 - val_accuracy: 0.9677 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1452 - accuracy: 0.9536 - val_loss: 0.1079 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1436 - accuracy: 0.9550 - val_loss: 0.1026 - val_accuracy: 0.9688 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.1401 - accuracy: 0.9556 - val_loss: 0.1055 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1376 - accuracy: 0.9555 - val_loss: 0.0983 - val_accuracy: 0.9700 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1347 - accuracy: 0.9568 - val_loss: 0.1027 - val_accuracy: 0.9706 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1346 - accuracy: 0.9565 - val_loss: 0.0978 - val_accuracy: 0.9709 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1298 - accuracy: 0.9596 - val_loss: 0.0980 - val_accuracy: 0.9708 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1241 - accuracy: 0.9596 - val_loss: 0.0999 - val_accuracy: 0.9708 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1237 - accuracy: 0.9600 - val_loss: 0.0958 - val_accuracy: 0.9706 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1238 - accuracy: 0.9593 - val_loss: 0.0940 - val_accuracy: 0.9710 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1263 - accuracy: 0.9591 - val_loss: 0.0927 - val_accuracy: 0.9717 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1152 - accuracy: 0.9615 - val_loss: 0.0934 - val_accuracy: 0.9723 - lr: 0.0010\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1147 - accuracy: 0.9624 - val_loss: 0.0951 - val_accuracy: 0.9727 - lr: 0.0010\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1143 - accuracy: 0.9617 - val_loss: 0.0912 - val_accuracy: 0.9727 - lr: 0.0010\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1196 - accuracy: 0.9614 - val_loss: 0.0950 - val_accuracy: 0.9719 - lr: 0.0010\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1137 - accuracy: 0.9625 - val_loss: 0.0960 - val_accuracy: 0.9722 - lr: 0.0010\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1106 - accuracy: 0.9634 - val_loss: 0.0912 - val_accuracy: 0.9737 - lr: 0.0010\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1046 - accuracy: 0.9644 - val_loss: 0.0918 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 42/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1112 - accuracy: 0.9639 - val_loss: 0.0913 - val_accuracy: 0.9733 - lr: 0.0010\n",
      "Epoch 43/150\n",
      "869/880 [============================>.] - ETA: 0s - loss: 0.1059 - accuracy: 0.9654\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1057 - accuracy: 0.9653 - val_loss: 0.0917 - val_accuracy: 0.9734 - lr: 0.0010\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1024 - accuracy: 0.9669 - val_loss: 0.0878 - val_accuracy: 0.9737 - lr: 7.0000e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0933 - accuracy: 0.9688 - val_loss: 0.0892 - val_accuracy: 0.9740 - lr: 7.0000e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0918 - accuracy: 0.9696 - val_loss: 0.0861 - val_accuracy: 0.9751 - lr: 7.0000e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0923 - accuracy: 0.9698 - val_loss: 0.0870 - val_accuracy: 0.9737 - lr: 7.0000e-04\n",
      "Epoch 48/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0888 - accuracy: 0.9706 - val_loss: 0.0878 - val_accuracy: 0.9749 - lr: 7.0000e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0916 - accuracy: 0.9687 - val_loss: 0.0848 - val_accuracy: 0.9757 - lr: 7.0000e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0899 - accuracy: 0.9703 - val_loss: 0.0854 - val_accuracy: 0.9742 - lr: 7.0000e-04\n",
      "Epoch 51/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0901 - accuracy: 0.9711 - val_loss: 0.0860 - val_accuracy: 0.9748 - lr: 7.0000e-04\n",
      "Epoch 52/150\n",
      "870/880 [============================>.] - ETA: 0s - loss: 0.0814 - accuracy: 0.9714\n",
      "Epoch 00052: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0817 - accuracy: 0.9714 - val_loss: 0.0860 - val_accuracy: 0.9750 - lr: 7.0000e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0841 - accuracy: 0.9718 - val_loss: 0.0869 - val_accuracy: 0.9755 - lr: 4.9000e-04\n",
      "Epoch 54/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0775 - accuracy: 0.9745 - val_loss: 0.0834 - val_accuracy: 0.9755 - lr: 4.9000e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0829 - accuracy: 0.9722 - val_loss: 0.0834 - val_accuracy: 0.9765 - lr: 4.9000e-04\n",
      "Epoch 56/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0784 - accuracy: 0.9743 - val_loss: 0.0843 - val_accuracy: 0.9755 - lr: 4.9000e-04\n",
      "Epoch 57/150\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.0761 - accuracy: 0.9731\n",
      "Epoch 00057: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0761 - accuracy: 0.9731 - val_loss: 0.0845 - val_accuracy: 0.9749 - lr: 4.9000e-04\n",
      "Epoch 58/150\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.0756 - accuracy: 0.9751 - val_loss: 0.0845 - val_accuracy: 0.9748 - lr: 3.4300e-04\n",
      "Epoch 59/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0737 - accuracy: 0.9764 - val_loss: 0.0843 - val_accuracy: 0.9749 - lr: 3.4300e-04\n",
      "Epoch 60/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0734 - accuracy: 0.9765 - val_loss: 0.0818 - val_accuracy: 0.9762 - lr: 3.4300e-04\n",
      "Epoch 61/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0738 - accuracy: 0.9743 - val_loss: 0.0831 - val_accuracy: 0.9765 - lr: 3.4300e-04\n",
      "Epoch 62/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0728 - accuracy: 0.9752 - val_loss: 0.0833 - val_accuracy: 0.9758 - lr: 3.4300e-04\n",
      "Epoch 63/150\n",
      "872/880 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 0.9768\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0676 - accuracy: 0.9768 - val_loss: 0.0839 - val_accuracy: 0.9760 - lr: 3.4300e-04\n",
      "Epoch 64/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0663 - accuracy: 0.9773 - val_loss: 0.0831 - val_accuracy: 0.9756 - lr: 2.4010e-04\n",
      "Epoch 65/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0695 - accuracy: 0.9769 - val_loss: 0.0840 - val_accuracy: 0.9762 - lr: 2.4010e-04\n",
      "Epoch 66/150\n",
      "875/880 [============================>.] - ETA: 0s - loss: 0.0652 - accuracy: 0.9780\n",
      "Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0651 - accuracy: 0.9781 - val_loss: 0.0829 - val_accuracy: 0.9766 - lr: 2.4010e-04\n",
      "Epoch 67/150\n",
      "880/880 [==============================] - 6s 7ms/step - loss: 0.0663 - accuracy: 0.9781 - val_loss: 0.0824 - val_accuracy: 0.9766 - lr: 1.6807e-04\n",
      "Epoch 68/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0650 - accuracy: 0.9785 - val_loss: 0.0834 - val_accuracy: 0.9772 - lr: 1.6807e-04\n",
      "Epoch 69/150\n",
      "867/880 [============================>.] - ETA: 0s - loss: 0.0640 - accuracy: 0.9787\n",
      "Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0646 - accuracy: 0.9785 - val_loss: 0.0820 - val_accuracy: 0.9772 - lr: 1.6807e-04\n",
      "Epoch 70/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0644 - accuracy: 0.9789 - val_loss: 0.0814 - val_accuracy: 0.9768 - lr: 1.1765e-04\n",
      "Epoch 71/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0645 - accuracy: 0.9784 - val_loss: 0.0816 - val_accuracy: 0.9765 - lr: 1.1765e-04\n",
      "Epoch 72/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0588 - accuracy: 0.9786 - val_loss: 0.0814 - val_accuracy: 0.9771 - lr: 1.1765e-04\n",
      "Epoch 73/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0616 - accuracy: 0.9790 - val_loss: 0.0811 - val_accuracy: 0.9771 - lr: 1.1765e-04\n",
      "Epoch 74/150\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.0633 - accuracy: 0.9791 - val_loss: 0.0821 - val_accuracy: 0.9771 - lr: 1.1765e-04\n",
      "Epoch 75/150\n",
      "880/880 [==============================] - 6s 7ms/step - loss: 0.0657 - accuracy: 0.9777 - val_loss: 0.0810 - val_accuracy: 0.9773 - lr: 1.1765e-04\n",
      "Epoch 76/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0599 - accuracy: 0.9803 - val_loss: 0.0818 - val_accuracy: 0.9776 - lr: 1.1765e-04\n",
      "Epoch 77/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0605 - accuracy: 0.9796 - val_loss: 0.0818 - val_accuracy: 0.9772 - lr: 1.1765e-04\n",
      "Epoch 78/150\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.0613 - accuracy: 0.9782\n",
      "Epoch 00078: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0614 - accuracy: 0.9782 - val_loss: 0.0823 - val_accuracy: 0.9771 - lr: 1.1765e-04\n",
      "Epoch 79/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0580 - accuracy: 0.9806 - val_loss: 0.0822 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 80/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0606 - accuracy: 0.9797 - val_loss: 0.0819 - val_accuracy: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 81/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0573 - accuracy: 0.9808 - val_loss: 0.0823 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 82/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0600 - accuracy: 0.9795 - val_loss: 0.0817 - val_accuracy: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 83/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0615 - accuracy: 0.9794 - val_loss: 0.0812 - val_accuracy: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 84/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 0.0819 - val_accuracy: 0.9770 - lr: 1.0000e-04\n",
      "Epoch 85/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0585 - accuracy: 0.9807 - val_loss: 0.0818 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "434/434 [==============================] - 1s 2ms/step - loss: 0.0810 - accuracy: 0.9773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.08096501231193542, 0.9772727489471436]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/95ab73206cbf4c5db672547efd4c476c\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [163]                 : (0.8325870633125305, 0.9807747006416321)\n",
      "COMET INFO:     batch_accuracy [14344]         : (0.0625, 1.0)\n",
      "COMET INFO:     batch_loss [14344]             : (0.0022980698850005865, 3.1722278594970703)\n",
      "COMET INFO:     epoch_duration [163]           : (3.3909999999996217, 6.031999999999243)\n",
      "COMET INFO:     loss [163]                     : (0.05687442794442177, 0.5359320044517517)\n",
      "COMET INFO:     lr [163]                       : (9.999999747378752e-05, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [163]             : (0.9157286882400513, 0.9776334762573242)\n",
      "COMET INFO:     val_loss [163]                 : (0.08096501231193542, 0.2739546298980713)\n",
      "COMET INFO:     validate_batch_accuracy [7172] : (0.9032738208770752, 1.0)\n",
      "COMET INFO:     validate_batch_loss [7172]     : (0.003870943561196327, 0.3674967586994171)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 3\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.05687442794442177\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 32, \"epochs\": 150, \"first_layer_dropout_rate\": 0.8, \"first_layer_units\": 750, \"second_layer_dropout_rate\": 0.1, \"second_layer_units\": 750, \"third_layer_dropout_rate\": 0.2, \"third_layer_units\": 100}\n",
      "COMET INFO:     optimizer_pid          : fa2bb71e33bb29a352dccdd31948ffc24b67d44a\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1234510\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 32\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.8\n",
      "COMET INFO:     first_layer_units         : 750\n",
      "COMET INFO:     second_layer_dropout_rate : 0.1\n",
      "COMET INFO:     second_layer_units        : 750\n",
      "COMET INFO:     steps                     : 880\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.2\n",
      "COMET INFO:     third_layer_units         : 100\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/cd9c2a77fcdc41d58ab9d90678667c2a\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "440/440 [==============================] - 3s 5ms/step - loss: 0.3842 - accuracy: 0.8835 - val_loss: 0.2243 - val_accuracy: 0.9318 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.2368 - accuracy: 0.9269 - val_loss: 0.1832 - val_accuracy: 0.9459 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.1936 - accuracy: 0.9384 - val_loss: 0.1619 - val_accuracy: 0.9510 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "440/440 [==============================] - 3s 6ms/step - loss: 0.1644 - accuracy: 0.9484 - val_loss: 0.1518 - val_accuracy: 0.9542 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.1430 - accuracy: 0.9541 - val_loss: 0.1489 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.1330 - accuracy: 0.9569 - val_loss: 0.1478 - val_accuracy: 0.9577 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.1195 - accuracy: 0.9613 - val_loss: 0.1454 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.1094 - accuracy: 0.9636 - val_loss: 0.1358 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.1031 - accuracy: 0.9650 - val_loss: 0.1216 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0939 - accuracy: 0.9683 - val_loss: 0.1294 - val_accuracy: 0.9657 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0893 - accuracy: 0.9709 - val_loss: 0.1319 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "430/440 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9711\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0839 - accuracy: 0.9711 - val_loss: 0.1260 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0633 - accuracy: 0.9780 - val_loss: 0.1180 - val_accuracy: 0.9673 - lr: 7.0000e-04\n",
      "Epoch 14/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0631 - accuracy: 0.9786 - val_loss: 0.1099 - val_accuracy: 0.9701 - lr: 7.0000e-04\n",
      "Epoch 15/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0601 - accuracy: 0.9793 - val_loss: 0.1203 - val_accuracy: 0.9669 - lr: 7.0000e-04\n",
      "Epoch 16/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0557 - accuracy: 0.9807 - val_loss: 0.1121 - val_accuracy: 0.9709 - lr: 7.0000e-04\n",
      "Epoch 17/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0492 - accuracy: 0.9830 - val_loss: 0.1075 - val_accuracy: 0.9701 - lr: 7.0000e-04\n",
      "Epoch 18/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0536 - accuracy: 0.9824 - val_loss: 0.1202 - val_accuracy: 0.9700 - lr: 7.0000e-04\n",
      "Epoch 19/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0496 - accuracy: 0.9832 - val_loss: 0.1185 - val_accuracy: 0.9702 - lr: 7.0000e-04\n",
      "Epoch 20/150\n",
      "436/440 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9848\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0446 - accuracy: 0.9849 - val_loss: 0.1174 - val_accuracy: 0.9712 - lr: 7.0000e-04\n",
      "Epoch 21/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0350 - accuracy: 0.9882 - val_loss: 0.1079 - val_accuracy: 0.9724 - lr: 4.9000e-04\n",
      "Epoch 22/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0351 - accuracy: 0.9877 - val_loss: 0.1107 - val_accuracy: 0.9729 - lr: 4.9000e-04\n",
      "Epoch 23/150\n",
      "438/440 [============================>.] - ETA: 0s - loss: 0.0298 - accuracy: 0.9893\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0298 - accuracy: 0.9894 - val_loss: 0.1161 - val_accuracy: 0.9724 - lr: 4.9000e-04\n",
      "Epoch 24/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0270 - accuracy: 0.9907 - val_loss: 0.1125 - val_accuracy: 0.9733 - lr: 3.4300e-04\n",
      "Epoch 25/150\n",
      "440/440 [==============================] - 2s 6ms/step - loss: 0.0268 - accuracy: 0.9906 - val_loss: 0.1140 - val_accuracy: 0.9749 - lr: 3.4300e-04\n",
      "Epoch 26/150\n",
      "431/440 [============================>.] - ETA: 0s - loss: 0.0256 - accuracy: 0.9911\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0255 - accuracy: 0.9911 - val_loss: 0.1093 - val_accuracy: 0.9741 - lr: 3.4300e-04\n",
      "Epoch 27/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0220 - accuracy: 0.9924 - val_loss: 0.1116 - val_accuracy: 0.9737 - lr: 2.4010e-04\n",
      "Epoch 1/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.3873 - accuracy: 0.8811 - val_loss: 0.2359 - val_accuracy: 0.9303 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2342 - accuracy: 0.9282 - val_loss: 0.2012 - val_accuracy: 0.9380 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1888 - accuracy: 0.9415 - val_loss: 0.1623 - val_accuracy: 0.9512 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1675 - accuracy: 0.9464 - val_loss: 0.1558 - val_accuracy: 0.9551 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1451 - accuracy: 0.9530 - val_loss: 0.1517 - val_accuracy: 0.9556 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1320 - accuracy: 0.9583 - val_loss: 0.1351 - val_accuracy: 0.9605 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1212 - accuracy: 0.9607 - val_loss: 0.1454 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1115 - accuracy: 0.9634 - val_loss: 0.1276 - val_accuracy: 0.9639 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1015 - accuracy: 0.9675 - val_loss: 0.1296 - val_accuracy: 0.9639 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0965 - accuracy: 0.9679 - val_loss: 0.1303 - val_accuracy: 0.9633 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "435/440 [============================>.] - ETA: 0s - loss: 0.0892 - accuracy: 0.9707\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0889 - accuracy: 0.9708 - val_loss: 0.1279 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0706 - accuracy: 0.9757 - val_loss: 0.1113 - val_accuracy: 0.9699 - lr: 7.0000e-04\n",
      "Epoch 13/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0614 - accuracy: 0.9794 - val_loss: 0.1139 - val_accuracy: 0.9694 - lr: 7.0000e-04\n",
      "Epoch 14/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0632 - accuracy: 0.9785 - val_loss: 0.1186 - val_accuracy: 0.9677 - lr: 7.0000e-04\n",
      "Epoch 15/150\n",
      "437/440 [============================>.] - ETA: 0s - loss: 0.0601 - accuracy: 0.9800\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0603 - accuracy: 0.9800 - val_loss: 0.1190 - val_accuracy: 0.9675 - lr: 7.0000e-04\n",
      "Epoch 16/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0476 - accuracy: 0.9839 - val_loss: 0.1059 - val_accuracy: 0.9720 - lr: 4.9000e-04\n",
      "Epoch 17/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0440 - accuracy: 0.9854 - val_loss: 0.1089 - val_accuracy: 0.9723 - lr: 4.9000e-04\n",
      "Epoch 18/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0428 - accuracy: 0.9854 - val_loss: 0.1133 - val_accuracy: 0.9729 - lr: 4.9000e-04\n",
      "Epoch 19/150\n",
      "438/440 [============================>.] - ETA: 0s - loss: 0.0380 - accuracy: 0.9881\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9881 - val_loss: 0.1134 - val_accuracy: 0.9719 - lr: 4.9000e-04\n",
      "Epoch 20/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.1094 - val_accuracy: 0.9745 - lr: 3.4300e-04\n",
      "Epoch 21/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0340 - accuracy: 0.9876 - val_loss: 0.1132 - val_accuracy: 0.9736 - lr: 3.4300e-04\n",
      "Epoch 22/150\n",
      "435/440 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9897\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0302 - accuracy: 0.9896 - val_loss: 0.1117 - val_accuracy: 0.9723 - lr: 3.4300e-04\n",
      "Epoch 23/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0285 - accuracy: 0.9905 - val_loss: 0.1088 - val_accuracy: 0.9738 - lr: 2.4010e-04\n",
      "Epoch 24/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0259 - accuracy: 0.9914 - val_loss: 0.1113 - val_accuracy: 0.9729 - lr: 2.4010e-04\n",
      "Epoch 25/150\n",
      "436/440 [============================>.] - ETA: 0s - loss: 0.0237 - accuracy: 0.9918\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0237 - accuracy: 0.9918 - val_loss: 0.1128 - val_accuracy: 0.9733 - lr: 2.4010e-04\n",
      "Epoch 26/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0224 - accuracy: 0.9924 - val_loss: 0.1105 - val_accuracy: 0.9742 - lr: 1.6807e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.1059 - accuracy: 0.9720\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.10585427284240723, 0.9720057845115662]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/cd9c2a77fcdc41d58ab9d90678667c2a\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [53]                  : (0.8810589909553528, 0.9923596382141113)\n",
      "COMET INFO:     batch_accuracy [2332]          : (0.0625, 1.0)\n",
      "COMET INFO:     batch_loss [2332]              : (0.0029413639567792416, 3.047638416290283)\n",
      "COMET INFO:     epoch_duration [53]            : (1.7040000000015425, 2.9059999999990396)\n",
      "COMET INFO:     loss [53]                      : (0.021979577839374542, 0.3872843384742737)\n",
      "COMET INFO:     lr [53]                        : (0.00016806999337859452, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [53]              : (0.9303030371665955, 0.9748917818069458)\n",
      "COMET INFO:     val_loss [53]                  : (0.10585431009531021, 0.23588047921657562)\n",
      "COMET INFO:     validate_batch_accuracy [1166] : (0.921875, 1.0)\n",
      "COMET INFO:     validate_batch_loss [1166]     : (0.006297210697084665, 0.24685584008693695)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 4\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.021979577839374542\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 64, \"epochs\": 150, \"first_layer_dropout_rate\": 0.4, \"first_layer_units\": 650, \"second_layer_dropout_rate\": 0.1, \"second_layer_units\": 650, \"third_layer_dropout_rate\": 0.2, \"third_layer_units\": 200}\n",
      "COMET INFO:     optimizer_pid          : e454e0a9b0429fd7fcd193194897f0ee56fe5bb8\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1071610\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 64\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.4\n",
      "COMET INFO:     first_layer_units         : 650\n",
      "COMET INFO:     second_layer_dropout_rate : 0.1\n",
      "COMET INFO:     second_layer_units        : 650\n",
      "COMET INFO:     steps                     : 440\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.2\n",
      "COMET INFO:     third_layer_units         : 200\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: Still uploading 2 file(s), remaining 14.19 KB/14.19 KB\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/bc33dc4f77fe41e7bbb63b11d3eecf1d\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "440/440 [==============================] - 3s 5ms/step - loss: 0.4720 - accuracy: 0.8614 - val_loss: 0.2511 - val_accuracy: 0.9252 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2998 - accuracy: 0.9113 - val_loss: 0.2053 - val_accuracy: 0.9384 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2399 - accuracy: 0.9277 - val_loss: 0.1728 - val_accuracy: 0.9486 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2007 - accuracy: 0.9405 - val_loss: 0.1590 - val_accuracy: 0.9509 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1807 - accuracy: 0.9450 - val_loss: 0.1499 - val_accuracy: 0.9538 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1651 - accuracy: 0.9509 - val_loss: 0.1412 - val_accuracy: 0.9596 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1431 - accuracy: 0.9558 - val_loss: 0.1366 - val_accuracy: 0.9604 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1345 - accuracy: 0.9587 - val_loss: 0.1364 - val_accuracy: 0.9606 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1204 - accuracy: 0.9625 - val_loss: 0.1256 - val_accuracy: 0.9650 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1159 - accuracy: 0.9639 - val_loss: 0.1262 - val_accuracy: 0.9642 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1060 - accuracy: 0.9670 - val_loss: 0.1150 - val_accuracy: 0.9681 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1041 - accuracy: 0.9672 - val_loss: 0.1228 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0997 - accuracy: 0.9693 - val_loss: 0.1224 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0912 - accuracy: 0.9707 - val_loss: 0.1149 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0874 - accuracy: 0.9711 - val_loss: 0.1232 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0833 - accuracy: 0.9735 - val_loss: 0.1150 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0745 - accuracy: 0.9759 - val_loss: 0.1076 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0733 - accuracy: 0.9760 - val_loss: 0.1183 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0711 - accuracy: 0.9758 - val_loss: 0.1145 - val_accuracy: 0.9694 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "435/440 [============================>.] - ETA: 0s - loss: 0.0675 - accuracy: 0.9779\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0679 - accuracy: 0.9778 - val_loss: 0.1157 - val_accuracy: 0.9709 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0550 - accuracy: 0.9822 - val_loss: 0.1034 - val_accuracy: 0.9732 - lr: 7.0000e-04\n",
      "Epoch 22/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0524 - accuracy: 0.9839 - val_loss: 0.1098 - val_accuracy: 0.9717 - lr: 7.0000e-04\n",
      "Epoch 23/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0520 - accuracy: 0.9822 - val_loss: 0.1064 - val_accuracy: 0.9716 - lr: 7.0000e-04\n",
      "Epoch 24/150\n",
      "438/440 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9840\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0494 - accuracy: 0.9840 - val_loss: 0.1075 - val_accuracy: 0.9735 - lr: 7.0000e-04\n",
      "Epoch 25/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0393 - accuracy: 0.9874 - val_loss: 0.1085 - val_accuracy: 0.9733 - lr: 4.9000e-04\n",
      "Epoch 26/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0416 - accuracy: 0.9871 - val_loss: 0.1005 - val_accuracy: 0.9742 - lr: 4.9000e-04\n",
      "Epoch 27/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0348 - accuracy: 0.9885 - val_loss: 0.1044 - val_accuracy: 0.9735 - lr: 4.9000e-04\n",
      "Epoch 28/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0365 - accuracy: 0.9877 - val_loss: 0.1072 - val_accuracy: 0.9733 - lr: 4.9000e-04\n",
      "Epoch 29/150\n",
      "432/440 [============================>.] - ETA: 0s - loss: 0.0367 - accuracy: 0.9884\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0367 - accuracy: 0.9884 - val_loss: 0.1034 - val_accuracy: 0.9746 - lr: 4.9000e-04\n",
      "Epoch 30/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0327 - accuracy: 0.9898 - val_loss: 0.1064 - val_accuracy: 0.9736 - lr: 3.4300e-04\n",
      "Epoch 31/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0324 - accuracy: 0.9888 - val_loss: 0.1078 - val_accuracy: 0.9748 - lr: 3.4300e-04\n",
      "Epoch 32/150\n",
      "427/440 [============================>.] - ETA: 0s - loss: 0.0284 - accuracy: 0.9904\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0286 - accuracy: 0.9904 - val_loss: 0.1066 - val_accuracy: 0.9754 - lr: 3.4300e-04\n",
      "Epoch 33/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0259 - accuracy: 0.9915 - val_loss: 0.1032 - val_accuracy: 0.9758 - lr: 2.4010e-04\n",
      "Epoch 34/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0256 - accuracy: 0.9916 - val_loss: 0.1047 - val_accuracy: 0.9757 - lr: 2.4010e-04\n",
      "Epoch 35/150\n",
      "440/440 [==============================] - ETA: 0s - loss: 0.0241 - accuracy: 0.9922\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 0.1046 - val_accuracy: 0.9762 - lr: 2.4010e-04\n",
      "Epoch 36/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0227 - accuracy: 0.9928 - val_loss: 0.1013 - val_accuracy: 0.9765 - lr: 1.6807e-04\n",
      "Epoch 1/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.4703 - accuracy: 0.8629 - val_loss: 0.2455 - val_accuracy: 0.9251 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2958 - accuracy: 0.9126 - val_loss: 0.2028 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2358 - accuracy: 0.9290 - val_loss: 0.1792 - val_accuracy: 0.9473 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2058 - accuracy: 0.9368 - val_loss: 0.1571 - val_accuracy: 0.9537 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1791 - accuracy: 0.9446 - val_loss: 0.1497 - val_accuracy: 0.9535 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1637 - accuracy: 0.9484 - val_loss: 0.1372 - val_accuracy: 0.9590 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1470 - accuracy: 0.9549 - val_loss: 0.1392 - val_accuracy: 0.9586 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1350 - accuracy: 0.9582 - val_loss: 0.1235 - val_accuracy: 0.9645 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1251 - accuracy: 0.9611 - val_loss: 0.1278 - val_accuracy: 0.9636 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1165 - accuracy: 0.9625 - val_loss: 0.1223 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1064 - accuracy: 0.9657 - val_loss: 0.1273 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0971 - accuracy: 0.9689 - val_loss: 0.1248 - val_accuracy: 0.9646 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0963 - accuracy: 0.9695 - val_loss: 0.1160 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0878 - accuracy: 0.9710 - val_loss: 0.1212 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0852 - accuracy: 0.9725 - val_loss: 0.1128 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0814 - accuracy: 0.9742 - val_loss: 0.1147 - val_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0776 - accuracy: 0.9753 - val_loss: 0.1152 - val_accuracy: 0.9686 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "432/440 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.9742\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0794 - accuracy: 0.9742 - val_loss: 0.1236 - val_accuracy: 0.9678 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0623 - accuracy: 0.9799 - val_loss: 0.1062 - val_accuracy: 0.9713 - lr: 7.0000e-04\n",
      "Epoch 20/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0573 - accuracy: 0.9814 - val_loss: 0.1111 - val_accuracy: 0.9718 - lr: 7.0000e-04\n",
      "Epoch 21/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0539 - accuracy: 0.9827 - val_loss: 0.1109 - val_accuracy: 0.9714 - lr: 7.0000e-04\n",
      "Epoch 22/150\n",
      "427/440 [============================>.] - ETA: 0s - loss: 0.0522 - accuracy: 0.9825\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0515 - accuracy: 0.9829 - val_loss: 0.1127 - val_accuracy: 0.9720 - lr: 7.0000e-04\n",
      "Epoch 23/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0438 - accuracy: 0.9853 - val_loss: 0.1040 - val_accuracy: 0.9730 - lr: 4.9000e-04\n",
      "Epoch 24/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0403 - accuracy: 0.9872 - val_loss: 0.1065 - val_accuracy: 0.9736 - lr: 4.9000e-04\n",
      "Epoch 25/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0384 - accuracy: 0.9881 - val_loss: 0.1075 - val_accuracy: 0.9742 - lr: 4.9000e-04\n",
      "Epoch 26/150\n",
      "433/440 [============================>.] - ETA: 0s - loss: 0.0389 - accuracy: 0.9866\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0393 - accuracy: 0.9865 - val_loss: 0.1057 - val_accuracy: 0.9742 - lr: 4.9000e-04\n",
      "Epoch 27/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0323 - accuracy: 0.9896 - val_loss: 0.1021 - val_accuracy: 0.9759 - lr: 3.4300e-04\n",
      "Epoch 28/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.1012 - val_accuracy: 0.9755 - lr: 3.4300e-04\n",
      "Epoch 29/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0334 - accuracy: 0.9892 - val_loss: 0.1030 - val_accuracy: 0.9755 - lr: 3.4300e-04\n",
      "Epoch 30/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0299 - accuracy: 0.9898 - val_loss: 0.1047 - val_accuracy: 0.9747 - lr: 3.4300e-04\n",
      "Epoch 31/150\n",
      "425/440 [===========================>..] - ETA: 0s - loss: 0.0323 - accuracy: 0.9888\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0322 - accuracy: 0.9888 - val_loss: 0.1068 - val_accuracy: 0.9755 - lr: 3.4300e-04\n",
      "Epoch 32/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0247 - accuracy: 0.9916 - val_loss: 0.1028 - val_accuracy: 0.9766 - lr: 2.4010e-04\n",
      "Epoch 33/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 0.0995 - val_accuracy: 0.9755 - lr: 2.4010e-04\n",
      "Epoch 34/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0256 - accuracy: 0.9921 - val_loss: 0.1007 - val_accuracy: 0.9766 - lr: 2.4010e-04\n",
      "Epoch 35/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0258 - accuracy: 0.9914 - val_loss: 0.1051 - val_accuracy: 0.9760 - lr: 2.4010e-04\n",
      "Epoch 36/150\n",
      "431/440 [============================>.] - ETA: 0s - loss: 0.0234 - accuracy: 0.9922\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0236 - accuracy: 0.9920 - val_loss: 0.1035 - val_accuracy: 0.9773 - lr: 2.4010e-04\n",
      "Epoch 37/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0211 - accuracy: 0.9925 - val_loss: 0.1037 - val_accuracy: 0.9767 - lr: 1.6807e-04\n",
      "Epoch 38/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0213 - accuracy: 0.9930 - val_loss: 0.1030 - val_accuracy: 0.9771 - lr: 1.6807e-04\n",
      "Epoch 39/150\n",
      "431/440 [============================>.] - ETA: 0s - loss: 0.0214 - accuracy: 0.9924\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0213 - accuracy: 0.9925 - val_loss: 0.1028 - val_accuracy: 0.9762 - lr: 1.6807e-04\n",
      "Epoch 40/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.1031 - val_accuracy: 0.9768 - lr: 1.1765e-04\n",
      "Epoch 41/150\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0199 - accuracy: 0.9936 - val_loss: 0.1031 - val_accuracy: 0.9763 - lr: 1.1765e-04\n",
      "Epoch 42/150\n",
      "436/440 [============================>.] - ETA: 0s - loss: 0.0189 - accuracy: 0.9941\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "440/440 [==============================] - 2s 5ms/step - loss: 0.0188 - accuracy: 0.9941 - val_loss: 0.1034 - val_accuracy: 0.9763 - lr: 1.1765e-04\n",
      "Epoch 43/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0179 - accuracy: 0.9946 - val_loss: 0.1047 - val_accuracy: 0.9764 - lr: 1.0000e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.0995 - accuracy: 0.9755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.09947291016578674, 0.9755411148071289]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/bc33dc4f77fe41e7bbb63b11d3eecf1d\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [79]                  : (0.8613716959953308, 0.9945984482765198)\n",
      "COMET INFO:     batch_accuracy [3476]          : (0.09375, 1.0)\n",
      "COMET INFO:     batch_loss [3476]              : (0.0021427974570542574, 2.8992862701416016)\n",
      "COMET INFO:     epoch_duration [79]            : (1.7040000000015425, 2.514999999999418)\n",
      "COMET INFO:     loss [79]                      : (0.017890596762299538, 0.47202473878860474)\n",
      "COMET INFO:     lr [79]                        : (9.999999747378752e-05, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [79]              : (0.9251082539558411, 0.9773448705673218)\n",
      "COMET INFO:     val_loss [79]                  : (0.09947290271520615, 0.2511369287967682)\n",
      "COMET INFO:     validate_batch_accuracy [1738] : (0.9180327653884888, 1.0)\n",
      "COMET INFO:     validate_batch_loss [1738]     : (0.003805382177233696, 0.2747490108013153)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 5\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.017890596762299538\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 64, \"epochs\": 150, \"first_layer_dropout_rate\": 0.4, \"first_layer_units\": 950, \"second_layer_dropout_rate\": 0.1, \"second_layer_units\": 300, \"third_layer_dropout_rate\": 0.4, \"third_layer_units\": 50}\n",
      "COMET INFO:     optimizer_pid          : 95f286bd7cdca3ebe6404e2511c02db08f65d713\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1051810\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 64\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.4\n",
      "COMET INFO:     first_layer_units         : 950\n",
      "COMET INFO:     second_layer_dropout_rate : 0.1\n",
      "COMET INFO:     second_layer_units        : 300\n",
      "COMET INFO:     steps                     : 440\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.4\n",
      "COMET INFO:     third_layer_units         : 50\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: Still uploading 2 file(s), remaining 14.19 KB/14.19 KB\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/a9137c6602db4aba880198bc782971b1\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.4771 - accuracy: 0.8545 - val_loss: 0.2419 - val_accuracy: 0.9258 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3025 - accuracy: 0.9059 - val_loss: 0.1870 - val_accuracy: 0.9429 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2586 - accuracy: 0.9173 - val_loss: 0.1700 - val_accuracy: 0.9474 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2320 - accuracy: 0.9274 - val_loss: 0.1619 - val_accuracy: 0.9516 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2142 - accuracy: 0.9319 - val_loss: 0.1594 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2003 - accuracy: 0.9362 - val_loss: 0.1405 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1908 - accuracy: 0.9393 - val_loss: 0.1376 - val_accuracy: 0.9583 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1688 - accuracy: 0.9468 - val_loss: 0.1274 - val_accuracy: 0.9608 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1664 - accuracy: 0.9463 - val_loss: 0.1201 - val_accuracy: 0.9639 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1543 - accuracy: 0.9499 - val_loss: 0.1332 - val_accuracy: 0.9607 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1488 - accuracy: 0.9522 - val_loss: 0.1220 - val_accuracy: 0.9634 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1416 - accuracy: 0.9550 - val_loss: 0.1181 - val_accuracy: 0.9647 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1314 - accuracy: 0.9566 - val_loss: 0.1149 - val_accuracy: 0.9656 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1270 - accuracy: 0.9580 - val_loss: 0.1148 - val_accuracy: 0.9660 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1289 - accuracy: 0.9585 - val_loss: 0.1056 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1252 - accuracy: 0.9598 - val_loss: 0.1081 - val_accuracy: 0.9673 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1145 - accuracy: 0.9627 - val_loss: 0.1018 - val_accuracy: 0.9703 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1134 - accuracy: 0.9633 - val_loss: 0.1079 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1034 - accuracy: 0.9669 - val_loss: 0.1128 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.1018 - accuracy: 0.9662\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1024 - accuracy: 0.9659 - val_loss: 0.1049 - val_accuracy: 0.9709 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0952 - accuracy: 0.9678 - val_loss: 0.0982 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0879 - accuracy: 0.9714 - val_loss: 0.0964 - val_accuracy: 0.9722 - lr: 7.0000e-04\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0824 - accuracy: 0.9726 - val_loss: 0.0970 - val_accuracy: 0.9733 - lr: 7.0000e-04\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0792 - accuracy: 0.9734 - val_loss: 0.0962 - val_accuracy: 0.9734 - lr: 7.0000e-04\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0812 - accuracy: 0.9730 - val_loss: 0.0921 - val_accuracy: 0.9739 - lr: 7.0000e-04\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0778 - accuracy: 0.9744 - val_loss: 0.0968 - val_accuracy: 0.9727 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0733 - accuracy: 0.9748 - val_loss: 0.1011 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 28/150\n",
      "878/880 [============================>.] - ETA: 0s - loss: 0.0730 - accuracy: 0.9764\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0729 - accuracy: 0.9764 - val_loss: 0.0987 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0627 - accuracy: 0.9796 - val_loss: 0.0931 - val_accuracy: 0.9743 - lr: 4.9000e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0582 - accuracy: 0.9806 - val_loss: 0.0933 - val_accuracy: 0.9750 - lr: 4.9000e-04\n",
      "Epoch 31/150\n",
      "874/880 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9785\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0630 - accuracy: 0.9785 - val_loss: 0.0927 - val_accuracy: 0.9745 - lr: 4.9000e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0559 - accuracy: 0.9810 - val_loss: 0.0903 - val_accuracy: 0.9745 - lr: 3.4300e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0543 - accuracy: 0.9815 - val_loss: 0.0870 - val_accuracy: 0.9761 - lr: 3.4300e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0506 - accuracy: 0.9813 - val_loss: 0.0910 - val_accuracy: 0.9757 - lr: 3.4300e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0534 - accuracy: 0.9821 - val_loss: 0.0894 - val_accuracy: 0.9758 - lr: 3.4300e-04\n",
      "Epoch 36/150\n",
      "876/880 [============================>.] - ETA: 0s - loss: 0.0495 - accuracy: 0.9828\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0496 - accuracy: 0.9827 - val_loss: 0.0898 - val_accuracy: 0.9762 - lr: 3.4300e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0484 - accuracy: 0.9839 - val_loss: 0.0873 - val_accuracy: 0.9768 - lr: 2.4010e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0440 - accuracy: 0.9845 - val_loss: 0.0864 - val_accuracy: 0.9769 - lr: 2.4010e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0440 - accuracy: 0.9853 - val_loss: 0.0875 - val_accuracy: 0.9763 - lr: 2.4010e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0429 - accuracy: 0.9855 - val_loss: 0.0888 - val_accuracy: 0.9758 - lr: 2.4010e-04\n",
      "Epoch 41/150\n",
      "867/880 [============================>.] - ETA: 0s - loss: 0.0442 - accuracy: 0.9837\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0444 - accuracy: 0.9836 - val_loss: 0.0877 - val_accuracy: 0.9767 - lr: 2.4010e-04\n",
      "Epoch 42/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0412 - accuracy: 0.9856 - val_loss: 0.0851 - val_accuracy: 0.9776 - lr: 1.6807e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0410 - accuracy: 0.9865 - val_loss: 0.0841 - val_accuracy: 0.9770 - lr: 1.6807e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0405 - accuracy: 0.9865 - val_loss: 0.0872 - val_accuracy: 0.9766 - lr: 1.6807e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0385 - accuracy: 0.9869 - val_loss: 0.0860 - val_accuracy: 0.9763 - lr: 1.6807e-04\n",
      "Epoch 46/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.0385 - accuracy: 0.9865\n",
      "Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0387 - accuracy: 0.9864 - val_loss: 0.0857 - val_accuracy: 0.9773 - lr: 1.6807e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0347 - accuracy: 0.9879 - val_loss: 0.0871 - val_accuracy: 0.9770 - lr: 1.1765e-04\n",
      "Epoch 48/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0361 - accuracy: 0.9876 - val_loss: 0.0860 - val_accuracy: 0.9774 - lr: 1.1765e-04\n",
      "Epoch 49/150\n",
      "876/880 [============================>.] - ETA: 0s - loss: 0.0338 - accuracy: 0.9884\n",
      "Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0338 - accuracy: 0.9884 - val_loss: 0.0863 - val_accuracy: 0.9777 - lr: 1.1765e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0339 - accuracy: 0.9885 - val_loss: 0.0852 - val_accuracy: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 51/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0319 - accuracy: 0.9889 - val_loss: 0.0847 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0363 - accuracy: 0.9875 - val_loss: 0.0835 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0335 - accuracy: 0.9883 - val_loss: 0.0849 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 54/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0341 - accuracy: 0.9876 - val_loss: 0.0862 - val_accuracy: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0352 - accuracy: 0.9882 - val_loss: 0.0850 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 56/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0344 - accuracy: 0.9886 - val_loss: 0.0842 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 57/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0313 - accuracy: 0.9894 - val_loss: 0.0847 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 58/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0298 - accuracy: 0.9896 - val_loss: 0.0861 - val_accuracy: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 59/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0318 - accuracy: 0.9889 - val_loss: 0.0854 - val_accuracy: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 60/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0301 - accuracy: 0.9893 - val_loss: 0.0861 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 61/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0320 - accuracy: 0.9890 - val_loss: 0.0854 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
      "Epoch 62/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0307 - accuracy: 0.9893 - val_loss: 0.0854 - val_accuracy: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 1/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.4702 - accuracy: 0.8576 - val_loss: 0.2376 - val_accuracy: 0.9277 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3044 - accuracy: 0.9051 - val_loss: 0.1923 - val_accuracy: 0.9427 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2616 - accuracy: 0.9179 - val_loss: 0.1759 - val_accuracy: 0.9475 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2343 - accuracy: 0.9273 - val_loss: 0.1604 - val_accuracy: 0.9519 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2145 - accuracy: 0.9340 - val_loss: 0.1564 - val_accuracy: 0.9509 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1974 - accuracy: 0.9366 - val_loss: 0.1466 - val_accuracy: 0.9553 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1845 - accuracy: 0.9402 - val_loss: 0.1472 - val_accuracy: 0.9552 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1737 - accuracy: 0.9439 - val_loss: 0.1283 - val_accuracy: 0.9621 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1622 - accuracy: 0.9491 - val_loss: 0.1302 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1547 - accuracy: 0.9498 - val_loss: 0.1215 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1428 - accuracy: 0.9533 - val_loss: 0.1331 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1373 - accuracy: 0.9538 - val_loss: 0.1125 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1357 - accuracy: 0.9561 - val_loss: 0.1146 - val_accuracy: 0.9661 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1266 - accuracy: 0.9599 - val_loss: 0.1238 - val_accuracy: 0.9630 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1243 - accuracy: 0.9602 - val_loss: 0.1073 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1172 - accuracy: 0.9613 - val_loss: 0.1124 - val_accuracy: 0.9671 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1155 - accuracy: 0.9616 - val_loss: 0.1050 - val_accuracy: 0.9704 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1085 - accuracy: 0.9639 - val_loss: 0.1094 - val_accuracy: 0.9701 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1042 - accuracy: 0.9651 - val_loss: 0.1053 - val_accuracy: 0.9699 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1056 - accuracy: 0.9658 - val_loss: 0.1033 - val_accuracy: 0.9707 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0979 - accuracy: 0.9683 - val_loss: 0.0964 - val_accuracy: 0.9711 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0984 - accuracy: 0.9675 - val_loss: 0.1058 - val_accuracy: 0.9706 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0927 - accuracy: 0.9706 - val_loss: 0.1036 - val_accuracy: 0.9708 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "869/880 [============================>.] - ETA: 0s - loss: 0.0925 - accuracy: 0.9693\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0920 - accuracy: 0.9694 - val_loss: 0.1037 - val_accuracy: 0.9699 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0815 - accuracy: 0.9717 - val_loss: 0.0911 - val_accuracy: 0.9745 - lr: 7.0000e-04\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0725 - accuracy: 0.9751 - val_loss: 0.0916 - val_accuracy: 0.9727 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0748 - accuracy: 0.9748 - val_loss: 0.0928 - val_accuracy: 0.9739 - lr: 7.0000e-04\n",
      "Epoch 28/150\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.0728 - accuracy: 0.9760\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0727 - accuracy: 0.9760 - val_loss: 0.0958 - val_accuracy: 0.9745 - lr: 7.0000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0650 - accuracy: 0.9784 - val_loss: 0.0911 - val_accuracy: 0.9737 - lr: 4.9000e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0650 - accuracy: 0.9787 - val_loss: 0.0911 - val_accuracy: 0.9739 - lr: 4.9000e-04\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0610 - accuracy: 0.9786 - val_loss: 0.0915 - val_accuracy: 0.9747 - lr: 4.9000e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0589 - accuracy: 0.9802 - val_loss: 0.0903 - val_accuracy: 0.9755 - lr: 4.9000e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0552 - accuracy: 0.9817 - val_loss: 0.0848 - val_accuracy: 0.9761 - lr: 4.9000e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0549 - accuracy: 0.9817 - val_loss: 0.0885 - val_accuracy: 0.9754 - lr: 4.9000e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0563 - accuracy: 0.9813 - val_loss: 0.0887 - val_accuracy: 0.9755 - lr: 4.9000e-04\n",
      "Epoch 36/150\n",
      "865/880 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9815\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0536 - accuracy: 0.9816 - val_loss: 0.0917 - val_accuracy: 0.9763 - lr: 4.9000e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0522 - accuracy: 0.9823 - val_loss: 0.0845 - val_accuracy: 0.9766 - lr: 3.4300e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0470 - accuracy: 0.9835 - val_loss: 0.0864 - val_accuracy: 0.9760 - lr: 3.4300e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0475 - accuracy: 0.9840 - val_loss: 0.0851 - val_accuracy: 0.9770 - lr: 3.4300e-04\n",
      "Epoch 40/150\n",
      "870/880 [============================>.] - ETA: 0s - loss: 0.0438 - accuracy: 0.9858\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0440 - accuracy: 0.9857 - val_loss: 0.0885 - val_accuracy: 0.9767 - lr: 3.4300e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0425 - accuracy: 0.9854 - val_loss: 0.0876 - val_accuracy: 0.9768 - lr: 2.4010e-04\n",
      "Epoch 42/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0425 - accuracy: 0.9849 - val_loss: 0.0857 - val_accuracy: 0.9768 - lr: 2.4010e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0408 - accuracy: 0.9866 - val_loss: 0.0841 - val_accuracy: 0.9784 - lr: 2.4010e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0389 - accuracy: 0.9867 - val_loss: 0.0853 - val_accuracy: 0.9781 - lr: 2.4010e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0352 - accuracy: 0.9884 - val_loss: 0.0844 - val_accuracy: 0.9785 - lr: 2.4010e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0409 - accuracy: 0.9856 - val_loss: 0.0827 - val_accuracy: 0.9786 - lr: 2.4010e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0398 - accuracy: 0.9870 - val_loss: 0.0857 - val_accuracy: 0.9773 - lr: 2.4010e-04\n",
      "Epoch 48/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0402 - accuracy: 0.9861 - val_loss: 0.0826 - val_accuracy: 0.9786 - lr: 2.4010e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0379 - accuracy: 0.9867 - val_loss: 0.0856 - val_accuracy: 0.9773 - lr: 2.4010e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0360 - accuracy: 0.9875 - val_loss: 0.0844 - val_accuracy: 0.9789 - lr: 2.4010e-04\n",
      "Epoch 51/150\n",
      "875/880 [============================>.] - ETA: 0s - loss: 0.0343 - accuracy: 0.9883\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0343 - accuracy: 0.9883 - val_loss: 0.0850 - val_accuracy: 0.9778 - lr: 2.4010e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0360 - accuracy: 0.9882 - val_loss: 0.0843 - val_accuracy: 0.9789 - lr: 1.6807e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0338 - accuracy: 0.9883 - val_loss: 0.0834 - val_accuracy: 0.9795 - lr: 1.6807e-04\n",
      "Epoch 54/150\n",
      "878/880 [============================>.] - ETA: 0s - loss: 0.0314 - accuracy: 0.9896\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0315 - accuracy: 0.9896 - val_loss: 0.0841 - val_accuracy: 0.9795 - lr: 1.6807e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0323 - accuracy: 0.9888 - val_loss: 0.0816 - val_accuracy: 0.9799 - lr: 1.1765e-04\n",
      "Epoch 56/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0322 - accuracy: 0.9889 - val_loss: 0.0834 - val_accuracy: 0.9789 - lr: 1.1765e-04\n",
      "Epoch 57/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0315 - accuracy: 0.9891 - val_loss: 0.0831 - val_accuracy: 0.9786 - lr: 1.1765e-04\n",
      "Epoch 58/150\n",
      "874/880 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9897\n",
      "Epoch 00058: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0303 - accuracy: 0.9897 - val_loss: 0.0842 - val_accuracy: 0.9789 - lr: 1.1765e-04\n",
      "Epoch 59/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0313 - accuracy: 0.9891 - val_loss: 0.0832 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 60/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0300 - accuracy: 0.9895 - val_loss: 0.0826 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 61/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0290 - accuracy: 0.9899 - val_loss: 0.0829 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 62/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 0.0832 - val_accuracy: 0.9796 - lr: 1.0000e-04\n",
      "Epoch 63/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0298 - accuracy: 0.9894 - val_loss: 0.0837 - val_accuracy: 0.9791 - lr: 1.0000e-04\n",
      "Epoch 64/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0299 - accuracy: 0.9894 - val_loss: 0.0841 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 65/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0296 - accuracy: 0.9897 - val_loss: 0.0823 - val_accuracy: 0.9795 - lr: 1.0000e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.0816 - accuracy: 0.9799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.08164311200380325, 0.9798701405525208]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/a9137c6602db4aba880198bc782971b1\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [127]                 : (0.85447758436203, 0.9899076223373413)\n",
      "COMET INFO:     batch_accuracy [11176]         : (0.03125, 1.0)\n",
      "COMET INFO:     batch_loss [11176]             : (0.00039475123048759997, 2.839698553085327)\n",
      "COMET INFO:     epoch_duration [127]           : (3.3429999999971187, 4.485000000000582)\n",
      "COMET INFO:     loss [127]                     : (0.02900533564388752, 0.47705280780792236)\n",
      "COMET INFO:     lr [127]                       : (9.999999747378752e-05, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [127]             : (0.9258297085762024, 0.9798701405525208)\n",
      "COMET INFO:     val_loss [127]                 : (0.08164311200380325, 0.24187788367271423)\n",
      "COMET INFO:     validate_batch_accuracy [5588] : (0.9119318127632141, 1.0)\n",
      "COMET INFO:     validate_batch_loss [5588]     : (0.0005332477740012109, 0.327762246131897)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 6\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.02900533564388752\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 32, \"epochs\": 150, \"first_layer_dropout_rate\": 0.7, \"first_layer_units\": 950, \"second_layer_dropout_rate\": 0.1, \"second_layer_units\": 600, \"third_layer_dropout_rate\": 0.1, \"third_layer_units\": 400}\n",
      "COMET INFO:     optimizer_pid          : 9848501446ff488cc3c923475abbe8e5a03d45ed\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1568560\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 32\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.7\n",
      "COMET INFO:     first_layer_units         : 950\n",
      "COMET INFO:     second_layer_dropout_rate : 0.1\n",
      "COMET INFO:     second_layer_units        : 600\n",
      "COMET INFO:     steps                     : 880\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.1\n",
      "COMET INFO:     third_layer_units         : 400\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/7ee3ed5e6318492c94f643c1658f38e2\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "440/440 [==============================] - 3s 5ms/step - loss: 0.4061 - accuracy: 0.8760 - val_loss: 0.2348 - val_accuracy: 0.9307 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2501 - accuracy: 0.9232 - val_loss: 0.1937 - val_accuracy: 0.9408 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2057 - accuracy: 0.9356 - val_loss: 0.1796 - val_accuracy: 0.9460 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1796 - accuracy: 0.9425 - val_loss: 0.1604 - val_accuracy: 0.9518 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1627 - accuracy: 0.9479 - val_loss: 0.1494 - val_accuracy: 0.9545 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1523 - accuracy: 0.9501 - val_loss: 0.1510 - val_accuracy: 0.9545 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1339 - accuracy: 0.9570 - val_loss: 0.1365 - val_accuracy: 0.9589 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1302 - accuracy: 0.9577 - val_loss: 0.1351 - val_accuracy: 0.9602 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1190 - accuracy: 0.9604 - val_loss: 0.1362 - val_accuracy: 0.9607 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1099 - accuracy: 0.9640 - val_loss: 0.1298 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1019 - accuracy: 0.9667 - val_loss: 0.1260 - val_accuracy: 0.9636 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0979 - accuracy: 0.9682 - val_loss: 0.1227 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0913 - accuracy: 0.9696 - val_loss: 0.1204 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0901 - accuracy: 0.9704 - val_loss: 0.1228 - val_accuracy: 0.9657 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0842 - accuracy: 0.9722 - val_loss: 0.1235 - val_accuracy: 0.9672 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0791 - accuracy: 0.9736 - val_loss: 0.1150 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0774 - accuracy: 0.9740 - val_loss: 0.1226 - val_accuracy: 0.9676 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0753 - accuracy: 0.9746 - val_loss: 0.1175 - val_accuracy: 0.9698 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "436/440 [============================>.] - ETA: 0s - loss: 0.0711 - accuracy: 0.9761\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0715 - accuracy: 0.9760 - val_loss: 0.1214 - val_accuracy: 0.9687 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0553 - accuracy: 0.9817 - val_loss: 0.1092 - val_accuracy: 0.9726 - lr: 7.0000e-04\n",
      "Epoch 21/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0555 - accuracy: 0.9811 - val_loss: 0.1105 - val_accuracy: 0.9705 - lr: 7.0000e-04\n",
      "Epoch 22/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0557 - accuracy: 0.9812 - val_loss: 0.1071 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 23/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0499 - accuracy: 0.9821 - val_loss: 0.1004 - val_accuracy: 0.9744 - lr: 7.0000e-04\n",
      "Epoch 24/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0478 - accuracy: 0.9843 - val_loss: 0.1084 - val_accuracy: 0.9713 - lr: 7.0000e-04\n",
      "Epoch 25/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0505 - accuracy: 0.9830 - val_loss: 0.1087 - val_accuracy: 0.9704 - lr: 7.0000e-04\n",
      "Epoch 26/150\n",
      "431/440 [============================>.] - ETA: 0s - loss: 0.0431 - accuracy: 0.9848\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0429 - accuracy: 0.9850 - val_loss: 0.1146 - val_accuracy: 0.9722 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0379 - accuracy: 0.9872 - val_loss: 0.1070 - val_accuracy: 0.9740 - lr: 4.9000e-04\n",
      "Epoch 28/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.9869 - val_loss: 0.1096 - val_accuracy: 0.9737 - lr: 4.9000e-04\n",
      "Epoch 29/150\n",
      "426/440 [============================>.] - ETA: 0s - loss: 0.0322 - accuracy: 0.9896\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0320 - accuracy: 0.9896 - val_loss: 0.1085 - val_accuracy: 0.9730 - lr: 4.9000e-04\n",
      "Epoch 30/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0292 - accuracy: 0.9898 - val_loss: 0.1028 - val_accuracy: 0.9745 - lr: 3.4300e-04\n",
      "Epoch 31/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0262 - accuracy: 0.9906 - val_loss: 0.1056 - val_accuracy: 0.9752 - lr: 3.4300e-04\n",
      "Epoch 32/150\n",
      "428/440 [============================>.] - ETA: 0s - loss: 0.0277 - accuracy: 0.9901\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0275 - accuracy: 0.9902 - val_loss: 0.1057 - val_accuracy: 0.9757 - lr: 3.4300e-04\n",
      "Epoch 33/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0221 - accuracy: 0.9920 - val_loss: 0.1054 - val_accuracy: 0.9762 - lr: 2.4010e-04\n",
      "Epoch 1/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.4043 - accuracy: 0.8790 - val_loss: 0.2359 - val_accuracy: 0.9294 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2488 - accuracy: 0.9210 - val_loss: 0.1886 - val_accuracy: 0.9425 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.2022 - accuracy: 0.9365 - val_loss: 0.1666 - val_accuracy: 0.9499 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1811 - accuracy: 0.9436 - val_loss: 0.1581 - val_accuracy: 0.9530 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1619 - accuracy: 0.9487 - val_loss: 0.1464 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1494 - accuracy: 0.9522 - val_loss: 0.1491 - val_accuracy: 0.9566 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1295 - accuracy: 0.9580 - val_loss: 0.1320 - val_accuracy: 0.9600 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1217 - accuracy: 0.9602 - val_loss: 0.1298 - val_accuracy: 0.9602 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1151 - accuracy: 0.9616 - val_loss: 0.1309 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1085 - accuracy: 0.9646 - val_loss: 0.1230 - val_accuracy: 0.9639 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.1074 - accuracy: 0.9638 - val_loss: 0.1265 - val_accuracy: 0.9639 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0983 - accuracy: 0.9667 - val_loss: 0.1196 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0939 - accuracy: 0.9687 - val_loss: 0.1241 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0885 - accuracy: 0.9706 - val_loss: 0.1257 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0798 - accuracy: 0.9730 - val_loss: 0.1150 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.9747 - val_loss: 0.1183 - val_accuracy: 0.9682 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0776 - accuracy: 0.9732 - val_loss: 0.1223 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0758 - accuracy: 0.9744 - val_loss: 0.1117 - val_accuracy: 0.9713 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0653 - accuracy: 0.9779 - val_loss: 0.1144 - val_accuracy: 0.9691 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0671 - accuracy: 0.9769 - val_loss: 0.1031 - val_accuracy: 0.9725 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0656 - accuracy: 0.9780 - val_loss: 0.1145 - val_accuracy: 0.9699 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0622 - accuracy: 0.9797 - val_loss: 0.1151 - val_accuracy: 0.9708 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "439/440 [============================>.] - ETA: 0s - loss: 0.0648 - accuracy: 0.9789\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0648 - accuracy: 0.9789 - val_loss: 0.1273 - val_accuracy: 0.9681 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0490 - accuracy: 0.9834 - val_loss: 0.1084 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 25/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0454 - accuracy: 0.9841 - val_loss: 0.1156 - val_accuracy: 0.9712 - lr: 7.0000e-04\n",
      "Epoch 26/150\n",
      "430/440 [============================>.] - ETA: 0s - loss: 0.0451 - accuracy: 0.9843\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0451 - accuracy: 0.9844 - val_loss: 0.1179 - val_accuracy: 0.9714 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9867 - val_loss: 0.1042 - val_accuracy: 0.9749 - lr: 4.9000e-04\n",
      "Epoch 28/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0324 - accuracy: 0.9885 - val_loss: 0.1041 - val_accuracy: 0.9737 - lr: 4.9000e-04\n",
      "Epoch 29/150\n",
      "431/440 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9885\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.9884 - val_loss: 0.1100 - val_accuracy: 0.9736 - lr: 4.9000e-04\n",
      "Epoch 30/150\n",
      "440/440 [==============================] - 2s 4ms/step - loss: 0.0298 - accuracy: 0.9898 - val_loss: 0.1057 - val_accuracy: 0.9742 - lr: 3.4300e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.1031 - accuracy: 0.9725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.10309232771396637, 0.972510814666748]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/7ee3ed5e6318492c94f643c1658f38e2\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [63]                  : (0.8760483264923096, 0.9920042753219604)\n",
      "COMET INFO:     batch_accuracy [2772]          : (0.0625, 1.0)\n",
      "COMET INFO:     batch_loss [2772]              : (0.00541919469833374, 2.8677945137023926)\n",
      "COMET INFO:     epoch_duration [63]            : (1.7340000000003783, 2.561999999998079)\n",
      "COMET INFO:     loss [63]                      : (0.02214827388525009, 0.40611276030540466)\n",
      "COMET INFO:     lr [63]                        : (0.00024009999469853938, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [63]              : (0.9294372200965881, 0.976190447807312)\n",
      "COMET INFO:     val_loss [63]                  : (0.100397028028965, 0.2359158843755722)\n",
      "COMET INFO:     validate_batch_accuracy [1386] : (0.9254331588745117, 1.0)\n",
      "COMET INFO:     validate_batch_loss [1386]     : (0.007475828751921654, 0.25137194991111755)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 7\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.02214827388525009\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 64, \"epochs\": 150, \"first_layer_dropout_rate\": 0.5, \"first_layer_units\": 750, \"second_layer_dropout_rate\": 0.2, \"second_layer_units\": 400, \"third_layer_dropout_rate\": 0.1, \"third_layer_units\": 400}\n",
      "COMET INFO:     optimizer_pid          : 7bd146f11bf492a6bf0b56ab54e336639d1a21f3\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1059760\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 64\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.5\n",
      "COMET INFO:     first_layer_units         : 750\n",
      "COMET INFO:     second_layer_dropout_rate : 0.2\n",
      "COMET INFO:     second_layer_units        : 400\n",
      "COMET INFO:     steps                     : 440\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.1\n",
      "COMET INFO:     third_layer_units         : 400\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/8147eba833944823994bd365cf3acbe8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.5202 - accuracy: 0.8389 - val_loss: 0.2600 - val_accuracy: 0.9206 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3719 - accuracy: 0.8846 - val_loss: 0.2267 - val_accuracy: 0.9293 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3278 - accuracy: 0.8978 - val_loss: 0.2035 - val_accuracy: 0.9381 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3015 - accuracy: 0.9056 - val_loss: 0.1904 - val_accuracy: 0.9428 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2787 - accuracy: 0.9136 - val_loss: 0.1816 - val_accuracy: 0.9434 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2660 - accuracy: 0.9163 - val_loss: 0.1680 - val_accuracy: 0.9483 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2538 - accuracy: 0.9188 - val_loss: 0.1566 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2323 - accuracy: 0.9266 - val_loss: 0.1551 - val_accuracy: 0.9519 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2284 - accuracy: 0.9272 - val_loss: 0.1432 - val_accuracy: 0.9560 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2206 - accuracy: 0.9314 - val_loss: 0.1446 - val_accuracy: 0.9564 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2062 - accuracy: 0.9346 - val_loss: 0.1387 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2013 - accuracy: 0.9371 - val_loss: 0.1327 - val_accuracy: 0.9594 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1948 - accuracy: 0.9382 - val_loss: 0.1288 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1865 - accuracy: 0.9415 - val_loss: 0.1250 - val_accuracy: 0.9625 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1858 - accuracy: 0.9410 - val_loss: 0.1238 - val_accuracy: 0.9618 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1785 - accuracy: 0.9423 - val_loss: 0.1201 - val_accuracy: 0.9629 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1752 - accuracy: 0.9439 - val_loss: 0.1202 - val_accuracy: 0.9639 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1665 - accuracy: 0.9471 - val_loss: 0.1178 - val_accuracy: 0.9627 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1635 - accuracy: 0.9495 - val_loss: 0.1121 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1582 - accuracy: 0.9490 - val_loss: 0.1083 - val_accuracy: 0.9665 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1587 - accuracy: 0.9502 - val_loss: 0.1110 - val_accuracy: 0.9675 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1537 - accuracy: 0.9503 - val_loss: 0.1104 - val_accuracy: 0.9652 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1508 - accuracy: 0.9514 - val_loss: 0.1063 - val_accuracy: 0.9681 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1443 - accuracy: 0.9523 - val_loss: 0.1017 - val_accuracy: 0.9690 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1374 - accuracy: 0.9539 - val_loss: 0.1025 - val_accuracy: 0.9695 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1387 - accuracy: 0.9548 - val_loss: 0.1009 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1370 - accuracy: 0.9563 - val_loss: 0.1014 - val_accuracy: 0.9696 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1380 - accuracy: 0.9549 - val_loss: 0.0976 - val_accuracy: 0.9694 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1337 - accuracy: 0.9564 - val_loss: 0.1020 - val_accuracy: 0.9699 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1277 - accuracy: 0.9583 - val_loss: 0.1006 - val_accuracy: 0.9691 - lr: 0.0010\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1271 - accuracy: 0.9576 - val_loss: 0.0943 - val_accuracy: 0.9720 - lr: 0.0010\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1264 - accuracy: 0.9591 - val_loss: 0.0998 - val_accuracy: 0.9697 - lr: 0.0010\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1223 - accuracy: 0.9601 - val_loss: 0.0976 - val_accuracy: 0.9702 - lr: 0.0010\n",
      "Epoch 34/150\n",
      "876/880 [============================>.] - ETA: 0s - loss: 0.1232 - accuracy: 0.9596\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1231 - accuracy: 0.9597 - val_loss: 0.0957 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1161 - accuracy: 0.9623 - val_loss: 0.0897 - val_accuracy: 0.9717 - lr: 7.0000e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1121 - accuracy: 0.9633 - val_loss: 0.0894 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1092 - accuracy: 0.9646 - val_loss: 0.0919 - val_accuracy: 0.9730 - lr: 7.0000e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1057 - accuracy: 0.9656 - val_loss: 0.0912 - val_accuracy: 0.9723 - lr: 7.0000e-04\n",
      "Epoch 39/150\n",
      "867/880 [============================>.] - ETA: 0s - loss: 0.1084 - accuracy: 0.9655\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1086 - accuracy: 0.9654 - val_loss: 0.0895 - val_accuracy: 0.9731 - lr: 7.0000e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1032 - accuracy: 0.9658 - val_loss: 0.0869 - val_accuracy: 0.9737 - lr: 4.9000e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0962 - accuracy: 0.9686 - val_loss: 0.0859 - val_accuracy: 0.9741 - lr: 4.9000e-04\n",
      "Epoch 42/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0971 - accuracy: 0.9680 - val_loss: 0.0841 - val_accuracy: 0.9750 - lr: 4.9000e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0947 - accuracy: 0.9682 - val_loss: 0.0862 - val_accuracy: 0.9747 - lr: 4.9000e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0922 - accuracy: 0.9699 - val_loss: 0.0864 - val_accuracy: 0.9737 - lr: 4.9000e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9697\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0914 - accuracy: 0.9697 - val_loss: 0.0861 - val_accuracy: 0.9752 - lr: 4.9000e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0916 - accuracy: 0.9699 - val_loss: 0.0858 - val_accuracy: 0.9745 - lr: 3.4300e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0900 - accuracy: 0.9705 - val_loss: 0.0851 - val_accuracy: 0.9750 - lr: 3.4300e-04\n",
      "Epoch 48/150\n",
      "874/880 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9725\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0822 - accuracy: 0.9726 - val_loss: 0.0850 - val_accuracy: 0.9747 - lr: 3.4300e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0839 - accuracy: 0.9725 - val_loss: 0.0844 - val_accuracy: 0.9753 - lr: 2.4010e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0816 - accuracy: 0.9727 - val_loss: 0.0860 - val_accuracy: 0.9750 - lr: 2.4010e-04\n",
      "Epoch 51/150\n",
      "870/880 [============================>.] - ETA: 0s - loss: 0.0826 - accuracy: 0.9724\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0824 - accuracy: 0.9726 - val_loss: 0.0850 - val_accuracy: 0.9755 - lr: 2.4010e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0841 - accuracy: 0.9725 - val_loss: 0.0854 - val_accuracy: 0.9756 - lr: 1.6807e-04\n",
      "Epoch 1/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.5225 - accuracy: 0.8369 - val_loss: 0.2668 - val_accuracy: 0.9201 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3785 - accuracy: 0.8834 - val_loss: 0.2279 - val_accuracy: 0.9294 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3264 - accuracy: 0.8974 - val_loss: 0.2046 - val_accuracy: 0.9389 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3028 - accuracy: 0.9049 - val_loss: 0.1870 - val_accuracy: 0.9429 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2766 - accuracy: 0.9125 - val_loss: 0.1805 - val_accuracy: 0.9449 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2622 - accuracy: 0.9158 - val_loss: 0.1614 - val_accuracy: 0.9509 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2462 - accuracy: 0.9230 - val_loss: 0.1598 - val_accuracy: 0.9501 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2385 - accuracy: 0.9236 - val_loss: 0.1614 - val_accuracy: 0.9519 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2298 - accuracy: 0.9276 - val_loss: 0.1483 - val_accuracy: 0.9548 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2159 - accuracy: 0.9318 - val_loss: 0.1384 - val_accuracy: 0.9559 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2057 - accuracy: 0.9348 - val_loss: 0.1423 - val_accuracy: 0.9574 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2027 - accuracy: 0.9360 - val_loss: 0.1334 - val_accuracy: 0.9588 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1937 - accuracy: 0.9378 - val_loss: 0.1297 - val_accuracy: 0.9610 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1908 - accuracy: 0.9385 - val_loss: 0.1285 - val_accuracy: 0.9613 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1846 - accuracy: 0.9414 - val_loss: 0.1221 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1822 - accuracy: 0.9429 - val_loss: 0.1224 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1745 - accuracy: 0.9442 - val_loss: 0.1193 - val_accuracy: 0.9641 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1695 - accuracy: 0.9458 - val_loss: 0.1213 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1626 - accuracy: 0.9482 - val_loss: 0.1177 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1596 - accuracy: 0.9475 - val_loss: 0.1172 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1558 - accuracy: 0.9502 - val_loss: 0.1172 - val_accuracy: 0.9644 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1483 - accuracy: 0.9510 - val_loss: 0.1135 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1499 - accuracy: 0.9525 - val_loss: 0.1086 - val_accuracy: 0.9668 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1512 - accuracy: 0.9523 - val_loss: 0.1082 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1440 - accuracy: 0.9533 - val_loss: 0.1042 - val_accuracy: 0.9670 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1431 - accuracy: 0.9535 - val_loss: 0.1015 - val_accuracy: 0.9697 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1361 - accuracy: 0.9556 - val_loss: 0.1039 - val_accuracy: 0.9692 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1361 - accuracy: 0.9559 - val_loss: 0.1015 - val_accuracy: 0.9680 - lr: 0.0010\n",
      "Epoch 29/150\n",
      "865/880 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.9566\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1321 - accuracy: 0.9565 - val_loss: 0.1028 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1264 - accuracy: 0.9586 - val_loss: 0.0955 - val_accuracy: 0.9707 - lr: 7.0000e-04\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1203 - accuracy: 0.9618 - val_loss: 0.0948 - val_accuracy: 0.9711 - lr: 7.0000e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1189 - accuracy: 0.9608 - val_loss: 0.1018 - val_accuracy: 0.9675 - lr: 7.0000e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1160 - accuracy: 0.9622 - val_loss: 0.0965 - val_accuracy: 0.9717 - lr: 7.0000e-04\n",
      "Epoch 34/150\n",
      "873/880 [============================>.] - ETA: 0s - loss: 0.1112 - accuracy: 0.9632\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1117 - accuracy: 0.9631 - val_loss: 0.1006 - val_accuracy: 0.9696 - lr: 7.0000e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1073 - accuracy: 0.9648 - val_loss: 0.0958 - val_accuracy: 0.9712 - lr: 4.9000e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1034 - accuracy: 0.9658 - val_loss: 0.0942 - val_accuracy: 0.9714 - lr: 4.9000e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1059 - accuracy: 0.9654 - val_loss: 0.0932 - val_accuracy: 0.9716 - lr: 4.9000e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1044 - accuracy: 0.9661 - val_loss: 0.0920 - val_accuracy: 0.9727 - lr: 4.9000e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1051 - accuracy: 0.9652 - val_loss: 0.0899 - val_accuracy: 0.9727 - lr: 4.9000e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0999 - accuracy: 0.9668 - val_loss: 0.0902 - val_accuracy: 0.9726 - lr: 4.9000e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0975 - accuracy: 0.9679 - val_loss: 0.0896 - val_accuracy: 0.9725 - lr: 4.9000e-04\n",
      "Epoch 42/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0972 - accuracy: 0.9682 - val_loss: 0.0881 - val_accuracy: 0.9738 - lr: 4.9000e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0971 - accuracy: 0.9686 - val_loss: 0.0893 - val_accuracy: 0.9731 - lr: 4.9000e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0947 - accuracy: 0.9682 - val_loss: 0.0908 - val_accuracy: 0.9725 - lr: 4.9000e-04\n",
      "Epoch 45/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.0948 - accuracy: 0.9672\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0944 - accuracy: 0.9672 - val_loss: 0.0906 - val_accuracy: 0.9726 - lr: 4.9000e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0901 - accuracy: 0.9701 - val_loss: 0.0895 - val_accuracy: 0.9737 - lr: 3.4300e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0896 - accuracy: 0.9701 - val_loss: 0.0893 - val_accuracy: 0.9740 - lr: 3.4300e-04\n",
      "Epoch 48/150\n",
      "865/880 [============================>.] - ETA: 0s - loss: 0.0860 - accuracy: 0.9721\n",
      "Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0858 - accuracy: 0.9721 - val_loss: 0.0884 - val_accuracy: 0.9743 - lr: 3.4300e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0842 - accuracy: 0.9721 - val_loss: 0.0888 - val_accuracy: 0.9740 - lr: 2.4010e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0883 - accuracy: 0.9710 - val_loss: 0.0884 - val_accuracy: 0.9734 - lr: 2.4010e-04\n",
      "Epoch 51/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0879 - accuracy: 0.9712 - val_loss: 0.0871 - val_accuracy: 0.9747 - lr: 2.4010e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0788 - accuracy: 0.9745 - val_loss: 0.0869 - val_accuracy: 0.9746 - lr: 2.4010e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0807 - accuracy: 0.9729 - val_loss: 0.0877 - val_accuracy: 0.9753 - lr: 2.4010e-04\n",
      "Epoch 54/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0836 - accuracy: 0.9720 - val_loss: 0.0875 - val_accuracy: 0.9754 - lr: 2.4010e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0804 - accuracy: 0.9728 - val_loss: 0.0864 - val_accuracy: 0.9755 - lr: 2.4010e-04\n",
      "Epoch 56/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0830 - accuracy: 0.9717 - val_loss: 0.0875 - val_accuracy: 0.9750 - lr: 2.4010e-04\n",
      "Epoch 57/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0794 - accuracy: 0.9741 - val_loss: 0.0877 - val_accuracy: 0.9747 - lr: 2.4010e-04\n",
      "Epoch 58/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0768 - accuracy: 0.9743 - val_loss: 0.0862 - val_accuracy: 0.9752 - lr: 2.4010e-04\n",
      "Epoch 59/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0792 - accuracy: 0.9745 - val_loss: 0.0865 - val_accuracy: 0.9748 - lr: 2.4010e-04\n",
      "Epoch 60/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0793 - accuracy: 0.9731 - val_loss: 0.0856 - val_accuracy: 0.9756 - lr: 2.4010e-04\n",
      "Epoch 61/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0787 - accuracy: 0.9732 - val_loss: 0.0857 - val_accuracy: 0.9757 - lr: 2.4010e-04\n",
      "Epoch 62/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0793 - accuracy: 0.9749 - val_loss: 0.0868 - val_accuracy: 0.9748 - lr: 2.4010e-04\n",
      "Epoch 63/150\n",
      "864/880 [============================>.] - ETA: 0s - loss: 0.0763 - accuracy: 0.9749\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0761 - accuracy: 0.9750 - val_loss: 0.0863 - val_accuracy: 0.9750 - lr: 2.4010e-04\n",
      "Epoch 64/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0716 - accuracy: 0.9756 - val_loss: 0.0865 - val_accuracy: 0.9750 - lr: 1.6807e-04\n",
      "Epoch 65/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0750 - accuracy: 0.9746 - val_loss: 0.0848 - val_accuracy: 0.9757 - lr: 1.6807e-04\n",
      "Epoch 66/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0727 - accuracy: 0.9762 - val_loss: 0.0854 - val_accuracy: 0.9755 - lr: 1.6807e-04\n",
      "Epoch 67/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0731 - accuracy: 0.9751 - val_loss: 0.0847 - val_accuracy: 0.9758 - lr: 1.6807e-04\n",
      "Epoch 68/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0716 - accuracy: 0.9755 - val_loss: 0.0850 - val_accuracy: 0.9762 - lr: 1.6807e-04\n",
      "Epoch 69/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0760 - accuracy: 0.9745 - val_loss: 0.0857 - val_accuracy: 0.9758 - lr: 1.6807e-04\n",
      "Epoch 70/150\n",
      "868/880 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 0.9746\n",
      "Epoch 00070: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0784 - accuracy: 0.9745 - val_loss: 0.0861 - val_accuracy: 0.9758 - lr: 1.6807e-04\n",
      "Epoch 71/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0707 - accuracy: 0.9767 - val_loss: 0.0847 - val_accuracy: 0.9766 - lr: 1.1765e-04\n",
      "Epoch 72/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0681 - accuracy: 0.9775 - val_loss: 0.0847 - val_accuracy: 0.9764 - lr: 1.1765e-04\n",
      "Epoch 73/150\n",
      "865/880 [============================>.] - ETA: 0s - loss: 0.0716 - accuracy: 0.9763\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0716 - accuracy: 0.9763 - val_loss: 0.0856 - val_accuracy: 0.9757 - lr: 1.1765e-04\n",
      "Epoch 74/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0683 - accuracy: 0.9769 - val_loss: 0.0855 - val_accuracy: 0.9755 - lr: 1.0000e-04\n",
      "Epoch 75/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0678 - accuracy: 0.9774 - val_loss: 0.0856 - val_accuracy: 0.9755 - lr: 1.0000e-04\n",
      "Epoch 76/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0690 - accuracy: 0.9765 - val_loss: 0.0849 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 77/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0684 - accuracy: 0.9767 - val_loss: 0.0843 - val_accuracy: 0.9760 - lr: 1.0000e-04\n",
      "Epoch 78/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0704 - accuracy: 0.9763 - val_loss: 0.0847 - val_accuracy: 0.9755 - lr: 1.0000e-04\n",
      "Epoch 79/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0700 - accuracy: 0.9777 - val_loss: 0.0837 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 80/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0657 - accuracy: 0.9780 - val_loss: 0.0834 - val_accuracy: 0.9763 - lr: 1.0000e-04\n",
      "Epoch 81/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0693 - accuracy: 0.9766 - val_loss: 0.0841 - val_accuracy: 0.9759 - lr: 1.0000e-04\n",
      "Epoch 82/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0701 - accuracy: 0.9775 - val_loss: 0.0844 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 83/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0710 - accuracy: 0.9758 - val_loss: 0.0845 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 84/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0668 - accuracy: 0.9766 - val_loss: 0.0844 - val_accuracy: 0.9760 - lr: 1.0000e-04\n",
      "Epoch 85/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0675 - accuracy: 0.9781 - val_loss: 0.0843 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 86/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.0842 - val_accuracy: 0.9755 - lr: 1.0000e-04\n",
      "Epoch 87/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0664 - accuracy: 0.9775 - val_loss: 0.0849 - val_accuracy: 0.9755 - lr: 1.0000e-04\n",
      "Epoch 88/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0666 - accuracy: 0.9779 - val_loss: 0.0842 - val_accuracy: 0.9760 - lr: 1.0000e-04\n",
      "Epoch 89/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0645 - accuracy: 0.9786 - val_loss: 0.0841 - val_accuracy: 0.9765 - lr: 1.0000e-04\n",
      "Epoch 90/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0684 - accuracy: 0.9775 - val_loss: 0.0851 - val_accuracy: 0.9763 - lr: 1.0000e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.0834 - accuracy: 0.9763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.08343587070703506, 0.976262629032135]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/8147eba833944823994bd365cf3acbe8\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [142]                 : (0.8369225263595581, 0.9786069393157959)\n",
      "COMET INFO:     batch_accuracy [12496]         : (0.03125, 1.0)\n",
      "COMET INFO:     batch_loss [12496]             : (0.0013098857598379254, 2.993527412414551)\n",
      "COMET INFO:     epoch_duration [142]           : (3.3439999999973224, 4.34400000000096)\n",
      "COMET INFO:     loss [142]                     : (0.06445460766553879, 0.5224553346633911)\n",
      "COMET INFO:     lr [142]                       : (9.999999747378752e-05, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [142]             : (0.9200577139854431, 0.9765512347221375)\n",
      "COMET INFO:     val_loss [142]                 : (0.08343587070703506, 0.26684510707855225)\n",
      "COMET INFO:     validate_batch_accuracy [6248] : (0.914977490901947, 1.0)\n",
      "COMET INFO:     validate_batch_loss [6248]     : (0.0021773171611130238, 0.35808467864990234)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 8\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.06445460766553879\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 32, \"epochs\": 150, \"first_layer_dropout_rate\": 0.8, \"first_layer_units\": 750, \"second_layer_dropout_rate\": 0.2, \"second_layer_units\": 500, \"third_layer_dropout_rate\": 0.1, \"third_layer_units\": 100}\n",
      "COMET INFO:     optimizer_pid          : 3921fcb32d26443e5949c6a5c45a8267264e4137\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1020760\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 32\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.8\n",
      "COMET INFO:     first_layer_units         : 750\n",
      "COMET INFO:     second_layer_dropout_rate : 0.2\n",
      "COMET INFO:     second_layer_units        : 500\n",
      "COMET INFO:     steps                     : 880\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.1\n",
      "COMET INFO:     third_layer_units         : 100\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/5fe16cefda15411fa78984a9e6e4d160\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  1/880 [..............................] - ETA: 6:54 - loss: 2.8743 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0042s vs `on_train_batch_end` time: 0.0052s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 4s 4ms/step - loss: 0.6122 - accuracy: 0.8083 - val_loss: 0.2833 - val_accuracy: 0.9143 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.4142 - accuracy: 0.8726 - val_loss: 0.2579 - val_accuracy: 0.9193 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.3673 - accuracy: 0.8869 - val_loss: 0.2345 - val_accuracy: 0.9280 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3403 - accuracy: 0.8962 - val_loss: 0.2058 - val_accuracy: 0.9351 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3115 - accuracy: 0.9025 - val_loss: 0.1950 - val_accuracy: 0.9382 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3010 - accuracy: 0.9064 - val_loss: 0.1919 - val_accuracy: 0.9412 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2804 - accuracy: 0.9112 - val_loss: 0.1868 - val_accuracy: 0.9424 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2730 - accuracy: 0.9134 - val_loss: 0.1806 - val_accuracy: 0.9462 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2603 - accuracy: 0.9180 - val_loss: 0.1627 - val_accuracy: 0.9490 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2556 - accuracy: 0.9191 - val_loss: 0.1656 - val_accuracy: 0.9495 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2482 - accuracy: 0.9216 - val_loss: 0.1601 - val_accuracy: 0.9508 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2345 - accuracy: 0.9260 - val_loss: 0.1484 - val_accuracy: 0.9543 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2303 - accuracy: 0.9259 - val_loss: 0.1462 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2315 - accuracy: 0.9270 - val_loss: 0.1432 - val_accuracy: 0.9553 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2188 - accuracy: 0.9313 - val_loss: 0.1423 - val_accuracy: 0.9562 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2171 - accuracy: 0.9317 - val_loss: 0.1381 - val_accuracy: 0.9588 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2082 - accuracy: 0.9338 - val_loss: 0.1369 - val_accuracy: 0.9582 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2080 - accuracy: 0.9357 - val_loss: 0.1337 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1971 - accuracy: 0.9381 - val_loss: 0.1333 - val_accuracy: 0.9585 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1976 - accuracy: 0.9375 - val_loss: 0.1280 - val_accuracy: 0.9613 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1953 - accuracy: 0.9384 - val_loss: 0.1298 - val_accuracy: 0.9605 - lr: 0.0010\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1915 - accuracy: 0.9384 - val_loss: 0.1253 - val_accuracy: 0.9618 - lr: 0.0010\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1903 - accuracy: 0.9390 - val_loss: 0.1299 - val_accuracy: 0.9597 - lr: 0.0010\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1810 - accuracy: 0.9421 - val_loss: 0.1232 - val_accuracy: 0.9622 - lr: 0.0010\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1827 - accuracy: 0.9426 - val_loss: 0.1234 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1744 - accuracy: 0.9453 - val_loss: 0.1234 - val_accuracy: 0.9626 - lr: 0.0010\n",
      "Epoch 27/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.1744 - accuracy: 0.9436\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1746 - accuracy: 0.9436 - val_loss: 0.1243 - val_accuracy: 0.9621 - lr: 0.0010\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1656 - accuracy: 0.9468 - val_loss: 0.1181 - val_accuracy: 0.9653 - lr: 7.0000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1650 - accuracy: 0.9486 - val_loss: 0.1118 - val_accuracy: 0.9661 - lr: 7.0000e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1582 - accuracy: 0.9474 - val_loss: 0.1142 - val_accuracy: 0.9665 - lr: 7.0000e-04\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1571 - accuracy: 0.9497 - val_loss: 0.1127 - val_accuracy: 0.9676 - lr: 7.0000e-04\n",
      "Epoch 32/150\n",
      "865/880 [============================>.] - ETA: 0s - loss: 0.1511 - accuracy: 0.9514\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1513 - accuracy: 0.9515 - val_loss: 0.1132 - val_accuracy: 0.9662 - lr: 7.0000e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1495 - accuracy: 0.9505 - val_loss: 0.1077 - val_accuracy: 0.9675 - lr: 4.9000e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1408 - accuracy: 0.9539 - val_loss: 0.1083 - val_accuracy: 0.9672 - lr: 4.9000e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1419 - accuracy: 0.9532 - val_loss: 0.1090 - val_accuracy: 0.9656 - lr: 4.9000e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1396 - accuracy: 0.9534 - val_loss: 0.1051 - val_accuracy: 0.9676 - lr: 4.9000e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1380 - accuracy: 0.9554 - val_loss: 0.1052 - val_accuracy: 0.9685 - lr: 4.9000e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1345 - accuracy: 0.9575 - val_loss: 0.1043 - val_accuracy: 0.9678 - lr: 4.9000e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1349 - accuracy: 0.9546 - val_loss: 0.1029 - val_accuracy: 0.9693 - lr: 4.9000e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1317 - accuracy: 0.9558 - val_loss: 0.1036 - val_accuracy: 0.9691 - lr: 4.9000e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1313 - accuracy: 0.9580 - val_loss: 0.1048 - val_accuracy: 0.9680 - lr: 4.9000e-04\n",
      "Epoch 42/150\n",
      "868/880 [============================>.] - ETA: 0s - loss: 0.1299 - accuracy: 0.9572\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1301 - accuracy: 0.9572 - val_loss: 0.1076 - val_accuracy: 0.9690 - lr: 4.9000e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1259 - accuracy: 0.9583 - val_loss: 0.1029 - val_accuracy: 0.9687 - lr: 3.4300e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1232 - accuracy: 0.9608 - val_loss: 0.1027 - val_accuracy: 0.9695 - lr: 3.4300e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1229 - accuracy: 0.9596 - val_loss: 0.1035 - val_accuracy: 0.9694 - lr: 3.4300e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1199 - accuracy: 0.9617 - val_loss: 0.1012 - val_accuracy: 0.9699 - lr: 3.4300e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1243 - accuracy: 0.9592 - val_loss: 0.1017 - val_accuracy: 0.9685 - lr: 3.4300e-04\n",
      "Epoch 48/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1190 - accuracy: 0.9609 - val_loss: 0.1013 - val_accuracy: 0.9699 - lr: 3.4300e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1169 - accuracy: 0.9617 - val_loss: 0.1005 - val_accuracy: 0.9709 - lr: 3.4300e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1173 - accuracy: 0.9618 - val_loss: 0.0996 - val_accuracy: 0.9712 - lr: 3.4300e-04\n",
      "Epoch 51/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1200 - accuracy: 0.9596 - val_loss: 0.0989 - val_accuracy: 0.9709 - lr: 3.4300e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1166 - accuracy: 0.9619 - val_loss: 0.0997 - val_accuracy: 0.9703 - lr: 3.4300e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1158 - accuracy: 0.9622 - val_loss: 0.1020 - val_accuracy: 0.9701 - lr: 3.4300e-04\n",
      "Epoch 54/150\n",
      "870/880 [============================>.] - ETA: 0s - loss: 0.1144 - accuracy: 0.9624\n",
      "Epoch 00054: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1142 - accuracy: 0.9624 - val_loss: 0.0997 - val_accuracy: 0.9713 - lr: 3.4300e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1123 - accuracy: 0.9641 - val_loss: 0.1000 - val_accuracy: 0.9704 - lr: 2.4010e-04\n",
      "Epoch 56/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1102 - accuracy: 0.9635 - val_loss: 0.0977 - val_accuracy: 0.9714 - lr: 2.4010e-04\n",
      "Epoch 57/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1059 - accuracy: 0.9654 - val_loss: 0.0975 - val_accuracy: 0.9714 - lr: 2.4010e-04\n",
      "Epoch 58/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1072 - accuracy: 0.9647 - val_loss: 0.0975 - val_accuracy: 0.9718 - lr: 2.4010e-04\n",
      "Epoch 59/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1098 - accuracy: 0.9640 - val_loss: 0.0986 - val_accuracy: 0.9719 - lr: 2.4010e-04\n",
      "Epoch 60/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1082 - accuracy: 0.9649 - val_loss: 0.0970 - val_accuracy: 0.9722 - lr: 2.4010e-04\n",
      "Epoch 61/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1088 - accuracy: 0.9633 - val_loss: 0.1004 - val_accuracy: 0.9696 - lr: 2.4010e-04\n",
      "Epoch 62/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1058 - accuracy: 0.9663 - val_loss: 0.0977 - val_accuracy: 0.9716 - lr: 2.4010e-04\n",
      "Epoch 63/150\n",
      "877/880 [============================>.] - ETA: 0s - loss: 0.1049 - accuracy: 0.9663\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1049 - accuracy: 0.9663 - val_loss: 0.0972 - val_accuracy: 0.9719 - lr: 2.4010e-04\n",
      "Epoch 64/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1061 - accuracy: 0.9653 - val_loss: 0.0960 - val_accuracy: 0.9721 - lr: 1.6807e-04\n",
      "Epoch 65/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1013 - accuracy: 0.9666 - val_loss: 0.0961 - val_accuracy: 0.9727 - lr: 1.6807e-04\n",
      "Epoch 66/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1001 - accuracy: 0.9670 - val_loss: 0.0967 - val_accuracy: 0.9721 - lr: 1.6807e-04\n",
      "Epoch 67/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1020 - accuracy: 0.9658 - val_loss: 0.0958 - val_accuracy: 0.9722 - lr: 1.6807e-04\n",
      "Epoch 68/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1016 - accuracy: 0.9664 - val_loss: 0.0950 - val_accuracy: 0.9730 - lr: 1.6807e-04\n",
      "Epoch 69/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1019 - accuracy: 0.9670 - val_loss: 0.0955 - val_accuracy: 0.9729 - lr: 1.6807e-04\n",
      "Epoch 70/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0996 - accuracy: 0.9681 - val_loss: 0.0943 - val_accuracy: 0.9729 - lr: 1.6807e-04\n",
      "Epoch 71/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1013 - accuracy: 0.9663 - val_loss: 0.0950 - val_accuracy: 0.9724 - lr: 1.6807e-04\n",
      "Epoch 72/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1039 - accuracy: 0.9664 - val_loss: 0.0945 - val_accuracy: 0.9717 - lr: 1.6807e-04\n",
      "Epoch 73/150\n",
      "878/880 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9673\n",
      "Epoch 00073: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0985 - accuracy: 0.9672 - val_loss: 0.0958 - val_accuracy: 0.9714 - lr: 1.6807e-04\n",
      "Epoch 74/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0949 - accuracy: 0.9692 - val_loss: 0.0949 - val_accuracy: 0.9733 - lr: 1.1765e-04\n",
      "Epoch 75/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0980 - accuracy: 0.9677 - val_loss: 0.0944 - val_accuracy: 0.9723 - lr: 1.1765e-04\n",
      "Epoch 76/150\n",
      "869/880 [============================>.] - ETA: 0s - loss: 0.0930 - accuracy: 0.9692\n",
      "Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0935 - accuracy: 0.9690 - val_loss: 0.0944 - val_accuracy: 0.9728 - lr: 1.1765e-04\n",
      "Epoch 77/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0953 - accuracy: 0.9679 - val_loss: 0.0946 - val_accuracy: 0.9727 - lr: 1.0000e-04\n",
      "Epoch 78/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0938 - accuracy: 0.9688 - val_loss: 0.0937 - val_accuracy: 0.9726 - lr: 1.0000e-04\n",
      "Epoch 79/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0923 - accuracy: 0.9693 - val_loss: 0.0947 - val_accuracy: 0.9731 - lr: 1.0000e-04\n",
      "Epoch 80/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0994 - accuracy: 0.9671 - val_loss: 0.0940 - val_accuracy: 0.9729 - lr: 1.0000e-04\n",
      "Epoch 81/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0919 - accuracy: 0.9693 - val_loss: 0.0943 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 82/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0963 - accuracy: 0.9679 - val_loss: 0.0933 - val_accuracy: 0.9733 - lr: 1.0000e-04\n",
      "Epoch 83/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0916 - accuracy: 0.9700 - val_loss: 0.0946 - val_accuracy: 0.9732 - lr: 1.0000e-04\n",
      "Epoch 84/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0993 - accuracy: 0.9676 - val_loss: 0.0941 - val_accuracy: 0.9728 - lr: 1.0000e-04\n",
      "Epoch 85/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0943 - accuracy: 0.9679 - val_loss: 0.0944 - val_accuracy: 0.9729 - lr: 1.0000e-04\n",
      "Epoch 86/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0886 - accuracy: 0.9703 - val_loss: 0.0941 - val_accuracy: 0.9729 - lr: 1.0000e-04\n",
      "Epoch 87/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0902 - accuracy: 0.9706 - val_loss: 0.0938 - val_accuracy: 0.9732 - lr: 1.0000e-04\n",
      "Epoch 88/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0912 - accuracy: 0.9689 - val_loss: 0.0939 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 89/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0928 - accuracy: 0.9704 - val_loss: 0.0941 - val_accuracy: 0.9726 - lr: 1.0000e-04\n",
      "Epoch 90/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0891 - accuracy: 0.9705 - val_loss: 0.0943 - val_accuracy: 0.9735 - lr: 1.0000e-04\n",
      "Epoch 91/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0883 - accuracy: 0.9699 - val_loss: 0.0959 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 92/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0892 - accuracy: 0.9705 - val_loss: 0.0951 - val_accuracy: 0.9729 - lr: 1.0000e-04\n",
      "Epoch 1/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.6125 - accuracy: 0.8112 - val_loss: 0.2921 - val_accuracy: 0.9112 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.4150 - accuracy: 0.8695 - val_loss: 0.2674 - val_accuracy: 0.9162 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3648 - accuracy: 0.8858 - val_loss: 0.2266 - val_accuracy: 0.9287 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3353 - accuracy: 0.8959 - val_loss: 0.2067 - val_accuracy: 0.9347 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.3119 - accuracy: 0.9042 - val_loss: 0.1929 - val_accuracy: 0.9424 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.3032 - accuracy: 0.9047 - val_loss: 0.1920 - val_accuracy: 0.9403 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2835 - accuracy: 0.9108 - val_loss: 0.1833 - val_accuracy: 0.9431 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2696 - accuracy: 0.9171 - val_loss: 0.1692 - val_accuracy: 0.9473 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2622 - accuracy: 0.9172 - val_loss: 0.1688 - val_accuracy: 0.9494 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2600 - accuracy: 0.9193 - val_loss: 0.1619 - val_accuracy: 0.9520 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2480 - accuracy: 0.9236 - val_loss: 0.1544 - val_accuracy: 0.9529 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2399 - accuracy: 0.9231 - val_loss: 0.1509 - val_accuracy: 0.9538 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2328 - accuracy: 0.9267 - val_loss: 0.1518 - val_accuracy: 0.9539 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2283 - accuracy: 0.9291 - val_loss: 0.1484 - val_accuracy: 0.9538 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2221 - accuracy: 0.9285 - val_loss: 0.1446 - val_accuracy: 0.9565 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2166 - accuracy: 0.9324 - val_loss: 0.1369 - val_accuracy: 0.9591 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2120 - accuracy: 0.9321 - val_loss: 0.1342 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2040 - accuracy: 0.9374 - val_loss: 0.1379 - val_accuracy: 0.9587 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2010 - accuracy: 0.9361 - val_loss: 0.1348 - val_accuracy: 0.9595 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "871/880 [============================>.] - ETA: 0s - loss: 0.1961 - accuracy: 0.9383\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1963 - accuracy: 0.9383 - val_loss: 0.1349 - val_accuracy: 0.9585 - lr: 0.0010\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1885 - accuracy: 0.9420 - val_loss: 0.1279 - val_accuracy: 0.9616 - lr: 7.0000e-04\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1774 - accuracy: 0.9440 - val_loss: 0.1232 - val_accuracy: 0.9638 - lr: 7.0000e-04\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1763 - accuracy: 0.9448 - val_loss: 0.1220 - val_accuracy: 0.9636 - lr: 7.0000e-04\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1758 - accuracy: 0.9455 - val_loss: 0.1234 - val_accuracy: 0.9630 - lr: 7.0000e-04\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1681 - accuracy: 0.9442 - val_loss: 0.1194 - val_accuracy: 0.9649 - lr: 7.0000e-04\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1631 - accuracy: 0.9477 - val_loss: 0.1154 - val_accuracy: 0.9652 - lr: 7.0000e-04\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1652 - accuracy: 0.9478 - val_loss: 0.1153 - val_accuracy: 0.9647 - lr: 7.0000e-04\n",
      "Epoch 28/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1606 - accuracy: 0.9484 - val_loss: 0.1156 - val_accuracy: 0.9649 - lr: 7.0000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1583 - accuracy: 0.9474 - val_loss: 0.1168 - val_accuracy: 0.9649 - lr: 7.0000e-04\n",
      "Epoch 30/150\n",
      "871/880 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 0.9498\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1578 - accuracy: 0.9499 - val_loss: 0.1195 - val_accuracy: 0.9642 - lr: 7.0000e-04\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1514 - accuracy: 0.9515 - val_loss: 0.1132 - val_accuracy: 0.9657 - lr: 4.9000e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1486 - accuracy: 0.9518 - val_loss: 0.1084 - val_accuracy: 0.9677 - lr: 4.9000e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1484 - accuracy: 0.9535 - val_loss: 0.1130 - val_accuracy: 0.9666 - lr: 4.9000e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1419 - accuracy: 0.9549 - val_loss: 0.1091 - val_accuracy: 0.9677 - lr: 4.9000e-04\n",
      "Epoch 35/150\n",
      "874/880 [============================>.] - ETA: 0s - loss: 0.1463 - accuracy: 0.9534\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1467 - accuracy: 0.9534 - val_loss: 0.1115 - val_accuracy: 0.9657 - lr: 4.9000e-04\n",
      "Epoch 36/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1342 - accuracy: 0.9573 - val_loss: 0.1059 - val_accuracy: 0.9692 - lr: 3.4300e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1329 - accuracy: 0.9571 - val_loss: 0.1055 - val_accuracy: 0.9691 - lr: 3.4300e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1292 - accuracy: 0.9587 - val_loss: 0.1067 - val_accuracy: 0.9689 - lr: 3.4300e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1311 - accuracy: 0.9562 - val_loss: 0.1031 - val_accuracy: 0.9697 - lr: 3.4300e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1271 - accuracy: 0.9592 - val_loss: 0.1056 - val_accuracy: 0.9685 - lr: 3.4300e-04\n",
      "Epoch 41/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1277 - accuracy: 0.9577 - val_loss: 0.1039 - val_accuracy: 0.9701 - lr: 3.4300e-04\n",
      "Epoch 42/150\n",
      "875/880 [============================>.] - ETA: 0s - loss: 0.1265 - accuracy: 0.9584\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1267 - accuracy: 0.9583 - val_loss: 0.1053 - val_accuracy: 0.9696 - lr: 3.4300e-04\n",
      "Epoch 43/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1211 - accuracy: 0.9610 - val_loss: 0.1032 - val_accuracy: 0.9699 - lr: 2.4010e-04\n",
      "Epoch 44/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1241 - accuracy: 0.9597 - val_loss: 0.1028 - val_accuracy: 0.9707 - lr: 2.4010e-04\n",
      "Epoch 45/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1258 - accuracy: 0.9585 - val_loss: 0.1023 - val_accuracy: 0.9698 - lr: 2.4010e-04\n",
      "Epoch 46/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1202 - accuracy: 0.9604 - val_loss: 0.1028 - val_accuracy: 0.9704 - lr: 2.4010e-04\n",
      "Epoch 47/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1163 - accuracy: 0.9614 - val_loss: 0.1020 - val_accuracy: 0.9693 - lr: 2.4010e-04\n",
      "Epoch 48/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1209 - accuracy: 0.9613 - val_loss: 0.1009 - val_accuracy: 0.9699 - lr: 2.4010e-04\n",
      "Epoch 49/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1146 - accuracy: 0.9633 - val_loss: 0.1028 - val_accuracy: 0.9707 - lr: 2.4010e-04\n",
      "Epoch 50/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1154 - accuracy: 0.9638 - val_loss: 0.1012 - val_accuracy: 0.9707 - lr: 2.4010e-04\n",
      "Epoch 51/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1157 - accuracy: 0.9612 - val_loss: 0.1000 - val_accuracy: 0.9713 - lr: 2.4010e-04\n",
      "Epoch 52/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1171 - accuracy: 0.9618 - val_loss: 0.1014 - val_accuracy: 0.9705 - lr: 2.4010e-04\n",
      "Epoch 53/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1113 - accuracy: 0.9630 - val_loss: 0.1004 - val_accuracy: 0.9701 - lr: 2.4010e-04\n",
      "Epoch 54/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1163 - accuracy: 0.9621 - val_loss: 0.0992 - val_accuracy: 0.9706 - lr: 2.4010e-04\n",
      "Epoch 55/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1142 - accuracy: 0.9624 - val_loss: 0.0984 - val_accuracy: 0.9722 - lr: 2.4010e-04\n",
      "Epoch 56/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1116 - accuracy: 0.9644 - val_loss: 0.0984 - val_accuracy: 0.9716 - lr: 2.4010e-04\n",
      "Epoch 57/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1071 - accuracy: 0.9645 - val_loss: 0.0997 - val_accuracy: 0.9716 - lr: 2.4010e-04\n",
      "Epoch 58/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1135 - accuracy: 0.9629 - val_loss: 0.0986 - val_accuracy: 0.9711 - lr: 2.4010e-04\n",
      "Epoch 59/150\n",
      "867/880 [============================>.] - ETA: 0s - loss: 0.1076 - accuracy: 0.9648\n",
      "Epoch 00059: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1071 - accuracy: 0.9650 - val_loss: 0.0995 - val_accuracy: 0.9704 - lr: 2.4010e-04\n",
      "Epoch 60/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1076 - accuracy: 0.9639 - val_loss: 0.0984 - val_accuracy: 0.9711 - lr: 1.6807e-04\n",
      "Epoch 61/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1067 - accuracy: 0.9649 - val_loss: 0.0986 - val_accuracy: 0.9716 - lr: 1.6807e-04\n",
      "Epoch 62/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1098 - accuracy: 0.9649 - val_loss: 0.0991 - val_accuracy: 0.9714 - lr: 1.6807e-04\n",
      "Epoch 63/150\n",
      "869/880 [============================>.] - ETA: 0s - loss: 0.1026 - accuracy: 0.9662\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1019 - accuracy: 0.9664 - val_loss: 0.0993 - val_accuracy: 0.9716 - lr: 1.6807e-04\n",
      "Epoch 64/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1054 - accuracy: 0.9636 - val_loss: 0.0987 - val_accuracy: 0.9716 - lr: 1.1765e-04\n",
      "Epoch 65/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1013 - accuracy: 0.9666 - val_loss: 0.0976 - val_accuracy: 0.9719 - lr: 1.1765e-04\n",
      "Epoch 66/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1053 - accuracy: 0.9650 - val_loss: 0.0976 - val_accuracy: 0.9713 - lr: 1.1765e-04\n",
      "Epoch 67/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1018 - accuracy: 0.9658 - val_loss: 0.0980 - val_accuracy: 0.9718 - lr: 1.1765e-04\n",
      "Epoch 68/150\n",
      "865/880 [============================>.] - ETA: 0s - loss: 0.1012 - accuracy: 0.9672\n",
      "Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1009 - accuracy: 0.9673 - val_loss: 0.0981 - val_accuracy: 0.9717 - lr: 1.1765e-04\n",
      "Epoch 69/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1027 - accuracy: 0.9668 - val_loss: 0.0979 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 70/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1013 - accuracy: 0.9677 - val_loss: 0.0985 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 71/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1064 - accuracy: 0.9641 - val_loss: 0.0977 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 72/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1020 - accuracy: 0.9683 - val_loss: 0.0991 - val_accuracy: 0.9709 - lr: 1.0000e-04\n",
      "Epoch 73/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1030 - accuracy: 0.9655 - val_loss: 0.0982 - val_accuracy: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 74/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0992 - accuracy: 0.9667 - val_loss: 0.0979 - val_accuracy: 0.9725 - lr: 1.0000e-04\n",
      "Epoch 75/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1008 - accuracy: 0.9672 - val_loss: 0.0974 - val_accuracy: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 76/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0986 - accuracy: 0.9676 - val_loss: 0.0975 - val_accuracy: 0.9711 - lr: 1.0000e-04\n",
      "Epoch 77/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0960 - accuracy: 0.9679 - val_loss: 0.0989 - val_accuracy: 0.9711 - lr: 1.0000e-04\n",
      "Epoch 78/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0973 - accuracy: 0.9675 - val_loss: 0.0984 - val_accuracy: 0.9715 - lr: 1.0000e-04\n",
      "Epoch 79/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1009 - accuracy: 0.9664 - val_loss: 0.0977 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 80/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0985 - accuracy: 0.9686 - val_loss: 0.0977 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 81/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0969 - accuracy: 0.9679 - val_loss: 0.0976 - val_accuracy: 0.9725 - lr: 1.0000e-04\n",
      "Epoch 82/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0910 - accuracy: 0.9694 - val_loss: 0.0975 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 83/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0954 - accuracy: 0.9688 - val_loss: 0.0975 - val_accuracy: 0.9725 - lr: 1.0000e-04\n",
      "Epoch 84/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0969 - accuracy: 0.9678 - val_loss: 0.0971 - val_accuracy: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 85/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0969 - accuracy: 0.9677 - val_loss: 0.0975 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 86/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0951 - accuracy: 0.9679 - val_loss: 0.0983 - val_accuracy: 0.9718 - lr: 1.0000e-04\n",
      "Epoch 87/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0976 - accuracy: 0.9675 - val_loss: 0.0979 - val_accuracy: 0.9716 - lr: 1.0000e-04\n",
      "Epoch 88/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0953 - accuracy: 0.9680 - val_loss: 0.0974 - val_accuracy: 0.9720 - lr: 1.0000e-04\n",
      "Epoch 89/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0920 - accuracy: 0.9688 - val_loss: 0.0971 - val_accuracy: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 90/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0940 - accuracy: 0.9679 - val_loss: 0.0970 - val_accuracy: 0.9728 - lr: 1.0000e-04\n",
      "Epoch 91/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0963 - accuracy: 0.9687 - val_loss: 0.0972 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 92/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0946 - accuracy: 0.9678 - val_loss: 0.0977 - val_accuracy: 0.9720 - lr: 1.0000e-04\n",
      "Epoch 93/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0941 - accuracy: 0.9686 - val_loss: 0.0958 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 94/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0974 - accuracy: 0.9668 - val_loss: 0.0976 - val_accuracy: 0.9717 - lr: 1.0000e-04\n",
      "Epoch 95/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0957 - accuracy: 0.9686 - val_loss: 0.0962 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 96/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0949 - accuracy: 0.9678 - val_loss: 0.0970 - val_accuracy: 0.9726 - lr: 1.0000e-04\n",
      "Epoch 97/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0919 - accuracy: 0.9688 - val_loss: 0.0974 - val_accuracy: 0.9727 - lr: 1.0000e-04\n",
      "Epoch 98/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0896 - accuracy: 0.9706 - val_loss: 0.0974 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 99/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0922 - accuracy: 0.9695 - val_loss: 0.0972 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 100/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0965 - accuracy: 0.9679 - val_loss: 0.0978 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "Epoch 101/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0905 - accuracy: 0.9706 - val_loss: 0.0965 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 102/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0925 - accuracy: 0.9699 - val_loss: 0.0959 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 103/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0949 - accuracy: 0.9685 - val_loss: 0.0957 - val_accuracy: 0.9726 - lr: 1.0000e-04\n",
      "Epoch 104/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0937 - accuracy: 0.9701 - val_loss: 0.0967 - val_accuracy: 0.9725 - lr: 1.0000e-04\n",
      "Epoch 105/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0907 - accuracy: 0.9705 - val_loss: 0.0960 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 106/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0886 - accuracy: 0.9700 - val_loss: 0.0960 - val_accuracy: 0.9721 - lr: 1.0000e-04\n",
      "Epoch 107/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0907 - accuracy: 0.9701 - val_loss: 0.0960 - val_accuracy: 0.9729 - lr: 1.0000e-04\n",
      "Epoch 108/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0937 - accuracy: 0.9700 - val_loss: 0.0971 - val_accuracy: 0.9723 - lr: 1.0000e-04\n",
      "Epoch 109/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0903 - accuracy: 0.9700 - val_loss: 0.0961 - val_accuracy: 0.9727 - lr: 1.0000e-04\n",
      "Epoch 110/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0933 - accuracy: 0.9690 - val_loss: 0.0961 - val_accuracy: 0.9732 - lr: 1.0000e-04\n",
      "Epoch 111/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0880 - accuracy: 0.9720 - val_loss: 0.0961 - val_accuracy: 0.9732 - lr: 1.0000e-04\n",
      "Epoch 112/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0894 - accuracy: 0.9697 - val_loss: 0.0973 - val_accuracy: 0.9727 - lr: 1.0000e-04\n",
      "Epoch 113/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0902 - accuracy: 0.9698 - val_loss: 0.0974 - val_accuracy: 0.9722 - lr: 1.0000e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.0957 - accuracy: 0.9726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.09570042043924332, 0.972582995891571]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/5fe16cefda15411fa78984a9e6e4d160\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [205]                 : (0.8082800507545471, 0.9719971418380737)\n",
      "COMET INFO:     batch_accuracy [18040]         : (0.0625, 1.0)\n",
      "COMET INFO:     batch_loss [18040]             : (0.005454329773783684, 2.944427490234375)\n",
      "COMET INFO:     epoch_duration [205]           : (3.375, 4.21900000000096)\n",
      "COMET INFO:     loss [205]                     : (0.08804254978895187, 0.612510085105896)\n",
      "COMET INFO:     lr [205]                       : (9.999999747378752e-05, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [205]             : (0.91118323802948, 0.9735209345817566)\n",
      "COMET INFO:     val_loss [205]                 : (0.09327928721904755, 0.2921002507209778)\n",
      "COMET INFO:     validate_batch_accuracy [9020] : (0.9056869149208069, 1.0)\n",
      "COMET INFO:     validate_batch_loss [9020]     : (0.007920421659946442, 0.4036279618740082)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 9\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.08804254978895187\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 32, \"epochs\": 150, \"first_layer_dropout_rate\": 0.8, \"first_layer_units\": 750, \"second_layer_dropout_rate\": 0.5, \"second_layer_units\": 450, \"third_layer_dropout_rate\": 0.2, \"third_layer_units\": 400}\n",
      "COMET INFO:     optimizer_pid          : 5f9182d4c7c5983c7264af8fa74f63a6c970b32c\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 1117510\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 32\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.8\n",
      "COMET INFO:     first_layer_units         : 750\n",
      "COMET INFO:     second_layer_dropout_rate : 0.5\n",
      "COMET INFO:     second_layer_units        : 450\n",
      "COMET INFO:     steps                     : 880\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.2\n",
      "COMET INFO:     third_layer_units         : 400\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n",
      "COMET WARNING: As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wodenwang820118/digit-recognizer/f29fa281ee454536b2e3fb8590345a2e\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "  1/880 [..............................] - ETA: 6:51 - loss: 2.6059 - accuracy: 0.0625"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0044s vs `on_train_batch_end` time: 0.0047s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "880/880 [==============================] - 4s 4ms/step - loss: 0.4623 - accuracy: 0.8613 - val_loss: 0.2556 - val_accuracy: 0.9227 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3020 - accuracy: 0.9096 - val_loss: 0.2017 - val_accuracy: 0.9386 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2477 - accuracy: 0.9256 - val_loss: 0.1764 - val_accuracy: 0.9457 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2172 - accuracy: 0.9333 - val_loss: 0.1547 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1884 - accuracy: 0.9417 - val_loss: 0.1414 - val_accuracy: 0.9563 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1737 - accuracy: 0.9465 - val_loss: 0.1317 - val_accuracy: 0.9592 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1604 - accuracy: 0.9494 - val_loss: 0.1256 - val_accuracy: 0.9623 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1420 - accuracy: 0.9543 - val_loss: 0.1233 - val_accuracy: 0.9640 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1344 - accuracy: 0.9574 - val_loss: 0.1181 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1254 - accuracy: 0.9605 - val_loss: 0.1253 - val_accuracy: 0.9628 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1187 - accuracy: 0.9627 - val_loss: 0.1204 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1141 - accuracy: 0.9632 - val_loss: 0.1099 - val_accuracy: 0.9681 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1001 - accuracy: 0.9672 - val_loss: 0.1203 - val_accuracy: 0.9662 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0967 - accuracy: 0.9695 - val_loss: 0.1122 - val_accuracy: 0.9677 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "878/880 [============================>.] - ETA: 0s - loss: 0.0941 - accuracy: 0.9706\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0942 - accuracy: 0.9706 - val_loss: 0.1126 - val_accuracy: 0.9683 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0794 - accuracy: 0.9740 - val_loss: 0.1048 - val_accuracy: 0.9711 - lr: 7.0000e-04\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0738 - accuracy: 0.9770 - val_loss: 0.1038 - val_accuracy: 0.9723 - lr: 7.0000e-04\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0690 - accuracy: 0.9778 - val_loss: 0.1026 - val_accuracy: 0.9724 - lr: 7.0000e-04\n",
      "Epoch 19/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0670 - accuracy: 0.9767 - val_loss: 0.1071 - val_accuracy: 0.9730 - lr: 7.0000e-04\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0650 - accuracy: 0.9788 - val_loss: 0.1019 - val_accuracy: 0.9737 - lr: 7.0000e-04\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0606 - accuracy: 0.9807 - val_loss: 0.1067 - val_accuracy: 0.9731 - lr: 7.0000e-04\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0587 - accuracy: 0.9802 - val_loss: 0.1027 - val_accuracy: 0.9734 - lr: 7.0000e-04\n",
      "Epoch 23/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.0580 - accuracy: 0.9805\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0580 - accuracy: 0.9805 - val_loss: 0.1085 - val_accuracy: 0.9719 - lr: 7.0000e-04\n",
      "Epoch 24/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0484 - accuracy: 0.9837 - val_loss: 0.0981 - val_accuracy: 0.9748 - lr: 4.9000e-04\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0455 - accuracy: 0.9846 - val_loss: 0.0948 - val_accuracy: 0.9763 - lr: 4.9000e-04\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0488 - accuracy: 0.9835 - val_loss: 0.0987 - val_accuracy: 0.9753 - lr: 4.9000e-04\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0420 - accuracy: 0.9855 - val_loss: 0.1017 - val_accuracy: 0.9747 - lr: 4.9000e-04\n",
      "Epoch 28/150\n",
      "865/880 [============================>.] - ETA: 0s - loss: 0.0424 - accuracy: 0.9861\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0423 - accuracy: 0.9861 - val_loss: 0.1040 - val_accuracy: 0.9747 - lr: 4.9000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0372 - accuracy: 0.9877 - val_loss: 0.0991 - val_accuracy: 0.9761 - lr: 3.4300e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0385 - accuracy: 0.9876 - val_loss: 0.0974 - val_accuracy: 0.9754 - lr: 3.4300e-04\n",
      "Epoch 31/150\n",
      "872/880 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9886\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0330 - accuracy: 0.9887 - val_loss: 0.0991 - val_accuracy: 0.9760 - lr: 3.4300e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 0.0975 - val_accuracy: 0.9776 - lr: 2.4010e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.1018 - val_accuracy: 0.9766 - lr: 2.4010e-04\n",
      "Epoch 34/150\n",
      "866/880 [============================>.] - ETA: 0s - loss: 0.0292 - accuracy: 0.9905\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.0997 - val_accuracy: 0.9772 - lr: 2.4010e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.0994 - val_accuracy: 0.9780 - lr: 1.6807e-04\n",
      "Epoch 1/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.4617 - accuracy: 0.8616 - val_loss: 0.2425 - val_accuracy: 0.9269 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.3088 - accuracy: 0.9069 - val_loss: 0.2036 - val_accuracy: 0.9387 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2481 - accuracy: 0.9256 - val_loss: 0.1796 - val_accuracy: 0.9455 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.2139 - accuracy: 0.9339 - val_loss: 0.1582 - val_accuracy: 0.9524 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1946 - accuracy: 0.9400 - val_loss: 0.1438 - val_accuracy: 0.9568 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1733 - accuracy: 0.9468 - val_loss: 0.1383 - val_accuracy: 0.9586 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1567 - accuracy: 0.9498 - val_loss: 0.1274 - val_accuracy: 0.9613 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1461 - accuracy: 0.9543 - val_loss: 0.1232 - val_accuracy: 0.9624 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1331 - accuracy: 0.9581 - val_loss: 0.1208 - val_accuracy: 0.9654 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1216 - accuracy: 0.9612 - val_loss: 0.1197 - val_accuracy: 0.9653 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1185 - accuracy: 0.9629 - val_loss: 0.1138 - val_accuracy: 0.9666 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.1120 - accuracy: 0.9631 - val_loss: 0.1185 - val_accuracy: 0.9659 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.1045 - accuracy: 0.9664 - val_loss: 0.1066 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0990 - accuracy: 0.9669 - val_loss: 0.1078 - val_accuracy: 0.9685 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0962 - accuracy: 0.9693 - val_loss: 0.1071 - val_accuracy: 0.9706 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0906 - accuracy: 0.9707 - val_loss: 0.1046 - val_accuracy: 0.9710 - lr: 0.0010\n",
      "Epoch 17/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0835 - accuracy: 0.9731 - val_loss: 0.1112 - val_accuracy: 0.9716 - lr: 0.0010\n",
      "Epoch 18/150\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0780 - accuracy: 0.9741 - val_loss: 0.1047 - val_accuracy: 0.9726 - lr: 0.0010\n",
      "Epoch 19/150\n",
      "875/880 [============================>.] - ETA: 0s - loss: 0.0783 - accuracy: 0.9747\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0782 - accuracy: 0.9746 - val_loss: 0.1072 - val_accuracy: 0.9721 - lr: 0.0010\n",
      "Epoch 20/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0636 - accuracy: 0.9783 - val_loss: 0.1036 - val_accuracy: 0.9725 - lr: 7.0000e-04\n",
      "Epoch 21/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0612 - accuracy: 0.9807 - val_loss: 0.1004 - val_accuracy: 0.9729 - lr: 7.0000e-04\n",
      "Epoch 22/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0562 - accuracy: 0.9807 - val_loss: 0.1027 - val_accuracy: 0.9742 - lr: 7.0000e-04\n",
      "Epoch 23/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0520 - accuracy: 0.9833 - val_loss: 0.1028 - val_accuracy: 0.9733 - lr: 7.0000e-04\n",
      "Epoch 24/150\n",
      "875/880 [============================>.] - ETA: 0s - loss: 0.0538 - accuracy: 0.9822\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0536 - accuracy: 0.9823 - val_loss: 0.1025 - val_accuracy: 0.9735 - lr: 7.0000e-04\n",
      "Epoch 25/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0474 - accuracy: 0.9839 - val_loss: 0.0974 - val_accuracy: 0.9760 - lr: 4.9000e-04\n",
      "Epoch 26/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0424 - accuracy: 0.9861 - val_loss: 0.0996 - val_accuracy: 0.9758 - lr: 4.9000e-04\n",
      "Epoch 27/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0421 - accuracy: 0.9857 - val_loss: 0.1015 - val_accuracy: 0.9761 - lr: 4.9000e-04\n",
      "Epoch 28/150\n",
      "877/880 [============================>.] - ETA: 0s - loss: 0.0390 - accuracy: 0.9868\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0390 - accuracy: 0.9868 - val_loss: 0.1009 - val_accuracy: 0.9763 - lr: 4.9000e-04\n",
      "Epoch 29/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0365 - accuracy: 0.9878 - val_loss: 0.0984 - val_accuracy: 0.9769 - lr: 3.4300e-04\n",
      "Epoch 30/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0329 - accuracy: 0.9895 - val_loss: 0.0970 - val_accuracy: 0.9769 - lr: 3.4300e-04\n",
      "Epoch 31/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0328 - accuracy: 0.9892 - val_loss: 0.0977 - val_accuracy: 0.9768 - lr: 3.4300e-04\n",
      "Epoch 32/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0353 - accuracy: 0.9879 - val_loss: 0.0993 - val_accuracy: 0.9771 - lr: 3.4300e-04\n",
      "Epoch 33/150\n",
      "880/880 [==============================] - ETA: 0s - loss: 0.0305 - accuracy: 0.9904\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0305 - accuracy: 0.9904 - val_loss: 0.0985 - val_accuracy: 0.9769 - lr: 3.4300e-04\n",
      "Epoch 34/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0274 - accuracy: 0.9907 - val_loss: 0.1019 - val_accuracy: 0.9763 - lr: 2.4010e-04\n",
      "Epoch 35/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0263 - accuracy: 0.9908 - val_loss: 0.1017 - val_accuracy: 0.9779 - lr: 2.4010e-04\n",
      "Epoch 36/150\n",
      "868/880 [============================>.] - ETA: 0s - loss: 0.0303 - accuracy: 0.9900\n",
      "Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0303 - accuracy: 0.9900 - val_loss: 0.1015 - val_accuracy: 0.9766 - lr: 2.4010e-04\n",
      "Epoch 37/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.1002 - val_accuracy: 0.9773 - lr: 1.6807e-04\n",
      "Epoch 38/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0251 - accuracy: 0.9910 - val_loss: 0.1001 - val_accuracy: 0.9769 - lr: 1.6807e-04\n",
      "Epoch 39/150\n",
      "880/880 [==============================] - ETA: 0s - loss: 0.0230 - accuracy: 0.9920\n",
      "Epoch 00039: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0230 - accuracy: 0.9920 - val_loss: 0.0995 - val_accuracy: 0.9775 - lr: 1.6807e-04\n",
      "Epoch 40/150\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0215 - accuracy: 0.9932 - val_loss: 0.0998 - val_accuracy: 0.9773 - lr: 1.1765e-04\n",
      "434/434 [==============================] - 1s 1ms/step - loss: 0.0970 - accuracy: 0.9769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: [0.09699351340532303, 0.9769119620323181]\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wodenwang820118/digit-recognizer/f29fa281ee454536b2e3fb8590345a2e\n",
      "COMET INFO:   Metrics [count] (min, max):\n",
      "COMET INFO:     accuracy [75]                  : (0.8612651228904724, 0.9932480454444885)\n",
      "COMET INFO:     batch_accuracy [6600]          : (0.0625, 1.0)\n",
      "COMET INFO:     batch_loss [6600]              : (0.001891818828880787, 3.096632719039917)\n",
      "COMET INFO:     epoch_duration [75]            : (3.375, 4.359000000000378)\n",
      "COMET INFO:     loss [75]                      : (0.021459097042679787, 0.4622652530670166)\n",
      "COMET INFO:     lr [75]                        : (0.00011764899682020769, 0.0010000000474974513)\n",
      "COMET INFO:     val_accuracy [75]              : (0.9227272868156433, 0.9779942035675049)\n",
      "COMET INFO:     val_loss [75]                  : (0.09482283890247345, 0.2555500268936157)\n",
      "COMET INFO:     validate_batch_accuracy [3300] : (0.9147727489471436, 1.0)\n",
      "COMET INFO:     validate_batch_loss [3300]     : (0.0011331565910950303, 0.3279849588871002)\n",
      "COMET INFO:   Others:\n",
      "COMET INFO:     optimizer_count        : 10\n",
      "COMET INFO:     optimizer_id           : d222a9ceb83e44b695c6f48cd870af98\n",
      "COMET INFO:     optimizer_metric       : loss\n",
      "COMET INFO:     optimizer_metric_value : 0.021459097042679787\n",
      "COMET INFO:     optimizer_objective    : minimum\n",
      "COMET INFO:     optimizer_parameters   : {\"batch_size\": 32, \"epochs\": 150, \"first_layer_dropout_rate\": 0.4, \"first_layer_units\": 600, \"second_layer_dropout_rate\": 0.1, \"second_layer_units\": 800, \"third_layer_dropout_rate\": 0.3, \"third_layer_units\": 50}\n",
      "COMET INFO:     optimizer_pid          : 7f33c79717ec367110d922a97e9a861c1fc56d73\n",
      "COMET INFO:     optimizer_process      : 26236\n",
      "COMET INFO:     optimizer_trial        : 1\n",
      "COMET INFO:     optimizer_version      : 2.0.1\n",
      "COMET INFO:     trainable_params       : 998160\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     Adam_amsgrad              : False\n",
      "COMET INFO:     Adam_beta_1               : 0.9\n",
      "COMET INFO:     Adam_beta_2               : 0.999\n",
      "COMET INFO:     Adam_decay                : 0.0\n",
      "COMET INFO:     Adam_epsilon              : 1e-07\n",
      "COMET INFO:     Adam_learning_rate        : 0.001\n",
      "COMET INFO:     Adam_name                 : Adam\n",
      "COMET INFO:     Optimizer                 : Adam\n",
      "COMET INFO:     batch_size                : 32\n",
      "COMET INFO:     epochs                    : 150\n",
      "COMET INFO:     first_layer_dropout_rate  : 0.4\n",
      "COMET INFO:     first_layer_units         : 600\n",
      "COMET INFO:     second_layer_dropout_rate : 0.1\n",
      "COMET INFO:     second_layer_units        : 800\n",
      "COMET INFO:     steps                     : 880\n",
      "COMET INFO:     third_layer_dropout_rate  : 0.3\n",
      "COMET INFO:     third_layer_units         : 50\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details : 1\n",
      "COMET INFO:     filename            : 1\n",
      "COMET INFO:     git metadata        : 1\n",
      "COMET INFO:     installed packages  : 1\n",
      "COMET INFO:     model graph         : 1\n",
      "COMET INFO:     notebook            : 1\n",
      "COMET INFO:     source_code         : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Uploading 1 metrics, params and output messages\n",
      "COMET INFO: Waiting for completion of the file uploads (may take several seconds)\n",
      "COMET INFO: The Python SDK has 10800 seconds to finish before aborting...\n",
      "COMET INFO: All files uploaded, waiting for confirmation they have been all received\n",
      "COMET INFO: Optimizer search d222a9ceb83e44b695c6f48cd870af98 has completed\n"
     ]
    }
   ],
   "source": [
    "classifier = DigitClassifier(X_train,X_test,y_train,y_test,early_stop,reduce_lr,experiment)\n",
    "# mu is the mean number of units, sigma is the standard deviation\n",
    "classifier.grid_search({\n",
    "    \"algorithm\": \"bayes\",\n",
    "    \"name\": \"Optimize Music Classification Network\",\n",
    "    \"spec\": {\"maxCombo\": 10, \"objective\": \"minimize\", \"metric\": \"loss\"},\n",
    "    \"parameters\": {\n",
    "        \"first_layer_units\": {\"type\": \"discrete\", \"values\": [450,500,550,600,650,700,750,800,850,900,950,1000]},\n",
    "        \"first_layer_dropout_rate\": {\"type\": \"discrete\", \"values\": [0.4,0.5,0.6,0.7,0.8]},\n",
    "        \"second_layer_units\": {\"type\": \"discrete\", \"values\": [300,400,450,500,550,600,650,700,750,800]},\n",
    "        \"second_layer_dropout_rate\": {\"type\": \"discrete\", \"values\": [0.1,0.2,0.3,0.4,0.5,0.6]},\n",
    "        \"third_layer_units\": {\"type\": \"discrete\", \"values\": [50,75,100,200,300,400,450]},\n",
    "        \"third_layer_dropout_rate\": {\"type\": \"discrete\", \"values\": [0.1,0.2,0.3,0.4]},\n",
    "        \"batch_size\": {\"type\": \"discrete\", \"values\": [32,64]},\n",
    "        \"epochs\": {\"type\": \"discrete\", \"values\": [150]},\n",
    "    },\n",
    "    \"trials\": 1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=950,\n",
    "        input_shape=(X_train.shape[1],)\n",
    "    )\n",
    ")\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Activation(activations.elu))\n",
    "model.add(Dropout(0.7))\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=600,\n",
    "        )\n",
    "    )\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Activation(activations.elu))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(\n",
    "    Dense(\n",
    "        units=400,\n",
    "        )\n",
    "    )\n",
    "model.add(BatchNormalization())\n",
    "model.add(layers.Activation(activations.elu))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "optimizer = keras.optimizers.Adam(0.001)\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "880/880 [==============================] - 5s 5ms/step - loss: 0.4705 - accuracy: 0.8566 - val_loss: 0.2434 - val_accuracy: 0.9234 - lr: 0.0010\n",
      "Epoch 2/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.3037 - accuracy: 0.9061 - val_loss: 0.1978 - val_accuracy: 0.9390 - lr: 0.0010\n",
      "Epoch 3/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2571 - accuracy: 0.9200 - val_loss: 0.1717 - val_accuracy: 0.9466 - lr: 0.0010\n",
      "Epoch 4/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2385 - accuracy: 0.9237 - val_loss: 0.1658 - val_accuracy: 0.9481 - lr: 0.0010\n",
      "Epoch 5/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.2179 - accuracy: 0.9311 - val_loss: 0.1528 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 6/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.2029 - accuracy: 0.9349 - val_loss: 0.1435 - val_accuracy: 0.9578 - lr: 0.0010\n",
      "Epoch 7/200\n",
      "880/880 [==============================] - 6s 6ms/step - loss: 0.1855 - accuracy: 0.9409 - val_loss: 0.1422 - val_accuracy: 0.9575 - lr: 0.0010\n",
      "Epoch 8/200\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.1750 - accuracy: 0.9453 - val_loss: 0.1328 - val_accuracy: 0.9605 - lr: 0.0010\n",
      "Epoch 9/200\n",
      "880/880 [==============================] - 6s 7ms/step - loss: 0.1627 - accuracy: 0.9482 - val_loss: 0.1263 - val_accuracy: 0.9610 - lr: 0.0010\n",
      "Epoch 10/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1572 - accuracy: 0.9495 - val_loss: 0.1252 - val_accuracy: 0.9631 - lr: 0.0010\n",
      "Epoch 11/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1465 - accuracy: 0.9515 - val_loss: 0.1197 - val_accuracy: 0.9638 - lr: 0.0010\n",
      "Epoch 12/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1372 - accuracy: 0.9556 - val_loss: 0.1138 - val_accuracy: 0.9653 - lr: 0.0010\n",
      "Epoch 13/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1352 - accuracy: 0.9563 - val_loss: 0.1182 - val_accuracy: 0.9637 - lr: 0.0010\n",
      "Epoch 14/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1290 - accuracy: 0.9566 - val_loss: 0.1167 - val_accuracy: 0.9667 - lr: 0.0010\n",
      "Epoch 15/200\n",
      "876/880 [============================>.] - ETA: 0s - loss: 0.1274 - accuracy: 0.9589\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0007000000332482159.\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1274 - accuracy: 0.9590 - val_loss: 0.1152 - val_accuracy: 0.9661 - lr: 0.0010\n",
      "Epoch 16/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.1077 - accuracy: 0.9645 - val_loss: 0.1043 - val_accuracy: 0.9691 - lr: 7.0000e-04\n",
      "Epoch 17/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0994 - accuracy: 0.9666 - val_loss: 0.0991 - val_accuracy: 0.9701 - lr: 7.0000e-04\n",
      "Epoch 18/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0960 - accuracy: 0.9678 - val_loss: 0.1044 - val_accuracy: 0.9696 - lr: 7.0000e-04\n",
      "Epoch 19/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0946 - accuracy: 0.9686 - val_loss: 0.1028 - val_accuracy: 0.9710 - lr: 7.0000e-04\n",
      "Epoch 20/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0881 - accuracy: 0.9711 - val_loss: 0.0961 - val_accuracy: 0.9724 - lr: 7.0000e-04\n",
      "Epoch 21/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0901 - accuracy: 0.9691 - val_loss: 0.0998 - val_accuracy: 0.9722 - lr: 7.0000e-04\n",
      "Epoch 22/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0861 - accuracy: 0.9706 - val_loss: 0.1029 - val_accuracy: 0.9695 - lr: 7.0000e-04\n",
      "Epoch 23/200\n",
      "874/880 [============================>.] - ETA: 0s - loss: 0.0808 - accuracy: 0.9728\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 0.0004900000232737511.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0809 - accuracy: 0.9728 - val_loss: 0.0969 - val_accuracy: 0.9714 - lr: 7.0000e-04\n",
      "Epoch 24/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0759 - accuracy: 0.9742 - val_loss: 0.0899 - val_accuracy: 0.9747 - lr: 4.9000e-04\n",
      "Epoch 25/200\n",
      "880/880 [==============================] - 5s 6ms/step - loss: 0.0728 - accuracy: 0.9754 - val_loss: 0.0884 - val_accuracy: 0.9754 - lr: 4.9000e-04\n",
      "Epoch 26/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0668 - accuracy: 0.9780 - val_loss: 0.0875 - val_accuracy: 0.9755 - lr: 4.9000e-04\n",
      "Epoch 27/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0704 - accuracy: 0.9772 - val_loss: 0.0900 - val_accuracy: 0.9742 - lr: 4.9000e-04\n",
      "Epoch 28/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0665 - accuracy: 0.9778 - val_loss: 0.0908 - val_accuracy: 0.9739 - lr: 4.9000e-04\n",
      "Epoch 29/200\n",
      "880/880 [==============================] - ETA: 0s - loss: 0.0632 - accuracy: 0.9785\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 0.00034300000406801696.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0632 - accuracy: 0.9785 - val_loss: 0.0966 - val_accuracy: 0.9734 - lr: 4.9000e-04\n",
      "Epoch 30/200\n",
      "880/880 [==============================] - 4s 5ms/step - loss: 0.0597 - accuracy: 0.9805 - val_loss: 0.0871 - val_accuracy: 0.9763 - lr: 3.4300e-04\n",
      "Epoch 31/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0544 - accuracy: 0.9813 - val_loss: 0.0899 - val_accuracy: 0.9755 - lr: 3.4300e-04\n",
      "Epoch 32/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0515 - accuracy: 0.9824 - val_loss: 0.0885 - val_accuracy: 0.9760 - lr: 3.4300e-04\n",
      "Epoch 33/200\n",
      "868/880 [============================>.] - ETA: 0s - loss: 0.0547 - accuracy: 0.9808\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.00024009999469853935.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0546 - accuracy: 0.9809 - val_loss: 0.0901 - val_accuracy: 0.9760 - lr: 3.4300e-04\n",
      "Epoch 34/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0496 - accuracy: 0.9841 - val_loss: 0.0866 - val_accuracy: 0.9760 - lr: 2.4010e-04\n",
      "Epoch 35/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0472 - accuracy: 0.9849 - val_loss: 0.0874 - val_accuracy: 0.9766 - lr: 2.4010e-04\n",
      "Epoch 36/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0482 - accuracy: 0.9838 - val_loss: 0.0845 - val_accuracy: 0.9777 - lr: 2.4010e-04\n",
      "Epoch 37/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0457 - accuracy: 0.9848 - val_loss: 0.0841 - val_accuracy: 0.9774 - lr: 2.4010e-04\n",
      "Epoch 38/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0492 - accuracy: 0.9832 - val_loss: 0.0861 - val_accuracy: 0.9763 - lr: 2.4010e-04\n",
      "Epoch 39/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0449 - accuracy: 0.9847 - val_loss: 0.0886 - val_accuracy: 0.9765 - lr: 2.4010e-04\n",
      "Epoch 40/200\n",
      "879/880 [============================>.] - ETA: 0s - loss: 0.0465 - accuracy: 0.9835\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.00016806999628897755.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0465 - accuracy: 0.9835 - val_loss: 0.0915 - val_accuracy: 0.9760 - lr: 2.4010e-04\n",
      "Epoch 41/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0433 - accuracy: 0.9861 - val_loss: 0.0861 - val_accuracy: 0.9771 - lr: 1.6807e-04\n",
      "Epoch 42/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0419 - accuracy: 0.9856 - val_loss: 0.0851 - val_accuracy: 0.9773 - lr: 1.6807e-04\n",
      "Epoch 43/200\n",
      "868/880 [============================>.] - ETA: 0s - loss: 0.0407 - accuracy: 0.9856\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.00011764899536501615.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0406 - accuracy: 0.9857 - val_loss: 0.0858 - val_accuracy: 0.9771 - lr: 1.6807e-04\n",
      "Epoch 44/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0371 - accuracy: 0.9873 - val_loss: 0.0840 - val_accuracy: 0.9772 - lr: 1.1765e-04\n",
      "Epoch 45/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0361 - accuracy: 0.9872 - val_loss: 0.0836 - val_accuracy: 0.9776 - lr: 1.1765e-04\n",
      "Epoch 46/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0364 - accuracy: 0.9872 - val_loss: 0.0840 - val_accuracy: 0.9779 - lr: 1.1765e-04\n",
      "Epoch 47/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0389 - accuracy: 0.9867 - val_loss: 0.0832 - val_accuracy: 0.9773 - lr: 1.1765e-04\n",
      "Epoch 48/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0384 - accuracy: 0.9873 - val_loss: 0.0835 - val_accuracy: 0.9785 - lr: 1.1765e-04\n",
      "Epoch 49/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0344 - accuracy: 0.9885 - val_loss: 0.0841 - val_accuracy: 0.9778 - lr: 1.1765e-04\n",
      "Epoch 50/200\n",
      "869/880 [============================>.] - ETA: 0s - loss: 0.0355 - accuracy: 0.9873\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0353 - accuracy: 0.9874 - val_loss: 0.0848 - val_accuracy: 0.9777 - lr: 1.1765e-04\n",
      "Epoch 51/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0353 - accuracy: 0.9889 - val_loss: 0.0855 - val_accuracy: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0355 - accuracy: 0.9869 - val_loss: 0.0849 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "880/880 [==============================] - 3s 4ms/step - loss: 0.0345 - accuracy: 0.9882 - val_loss: 0.0846 - val_accuracy: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0342 - accuracy: 0.9890 - val_loss: 0.0845 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 55/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0359 - accuracy: 0.9880 - val_loss: 0.0840 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 56/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0345 - accuracy: 0.9881 - val_loss: 0.0840 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
      "Epoch 57/200\n",
      "880/880 [==============================] - 4s 4ms/step - loss: 0.0327 - accuracy: 0.9886 - val_loss: 0.0835 - val_accuracy: 0.9781 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f33f82f730>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train,batch_size=32,epochs=200,validation_data=(X_test,y_test),callbacks=[early_stop,reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "434/434 [==============================] - 1s 2ms/step - loss: 0.0832 - accuracy: 0.9773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08322234451770782, 0.9773448705673218]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test.csv')\n",
    "# scale the numeric data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "test_data = scaler.fit_transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(prediction, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame(np.arange(1,len(labels)+1), columns=['ImageId'])\n",
    "df_result['label']=labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ImageId</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ImageId  label\n",
       "0        1      2\n",
       "1        2      0\n",
       "2        3      9\n",
       "3        4      9\n",
       "4        5      3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv('submission_nn_comet_keras.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "984944ce4eefbed249e2a3501e72ee0777f56e66d10a0a53283275062444400f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
